{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Setup\n",
    "\n",
    "This Jupyter notebook demonstrates the development of a virtual doctor chatbot that interacts with heart failure patients \n",
    "to monitor their progress. The chatbot uses LangChain and GPT-3.5 for natural language processing and response generation.\n",
    "\n",
    "Components:\n",
    "1. User Interface (UI): The primary interface for patient interaction.\n",
    "2. Conversational AI Core (GPT-3.5): Processes user input and generates responses.\n",
    "3. Dialogue Manager: Manages user sessions and ensures a logical conversation flow.\n",
    "4. Simulation Toggle: Allows switching between user interaction and simulated patient interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from typing import List, Callable\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from typing import List, Callable\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file\n",
    "ROOT_DIR = \".\"  # Set this to the root directory where your .env file is located\n",
    "load_dotenv(os.path.join(ROOT_DIR, \".env\"))\n",
    "\n",
    "# Set up unique ID for session\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "# Set environment variables for LangChain\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"HeartFailureMonitor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInterface:\n",
    "    def __init__(self, simulation_mode: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the User Interface with the given simulation mode.\n",
    "\n",
    "        Args:\n",
    "            simulation_mode (bool, optional): Whether to start in simulation mode. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.simulation_mode = simulation_mode  # By default, start in user input mode\n",
    "    \n",
    "    def set_simulation_mode(self, simulation_mode: bool):\n",
    "        \"\"\"\n",
    "        Set the simulation mode of the User Interface.\n",
    "\n",
    "        Args:\n",
    "            simulation_mode (bool): Whether to start in simulation mode.\n",
    "        \"\"\"\n",
    "        self.simulation_mode = simulation_mode\n",
    "        mode = \"Simulation Mode\" if self.simulation_mode else \"User Input Mode\"\n",
    "        print(f\"Mode toggled to: {mode}\")\n",
    "        \n",
    "    def collect_user_input(self):\n",
    "        \"\"\"\n",
    "        Collects user input.\n",
    "\n",
    "        Returns:\n",
    "            str: The user input.\n",
    "        \"\"\"\n",
    "        if not self.simulation_mode:\n",
    "            user_input = input(\"Enter user message. Enter 'exit' to stop chat: \")\n",
    "            return user_input\n",
    "        else:\n",
    "            print(\"Simulation mode is ON. User input is disabled.\")\n",
    "            return None\n",
    "\n",
    "    def display_response(self, response: str):\n",
    "        \"\"\"\n",
    "        Displays the response to the user.\n",
    "\n",
    "        Args:\n",
    "            response (str): The response to display.\n",
    "        \"\"\"\n",
    "        print(f\"Agent's Response: {response}\")\n",
    "\n",
    "# Initialize the UI\n",
    "ui = UserInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Dialogue Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(self, name: str, system_message: str, model: ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo')) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the DialogueAgent with a name, system message, and a language model.\n",
    "        \n",
    "        Args:\n",
    "            name (str): The name of the agent.\n",
    "            system_message (str): The initial system message to set the context.\n",
    "            model (ChatOpenAI): The language model to use for generating responses.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "\n",
    "        # Initialize chat message history to keep track of the entire conversation\n",
    "        self.memory = ChatMessageHistory()\n",
    "        \n",
    "        # Define the prompt template with placeholders.\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                SystemMessage(content=self.system_message),  # The persistent system prompt\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),  # Where the memory will be stored.\n",
    "                HumanMessagePromptTemplate.from_template(\"{human_input}\"),  # Where the human input will be injected\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Define the LLM chain with the model and prompt\n",
    "        self.chain = LLMChain(\n",
    "            llm=self.model,\n",
    "            prompt=self.prompt,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Initialize the memory with the system message\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the conversation history in memory\n",
    "        \"\"\"\n",
    "        self.memory.clear()\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Generates a response based on the conversation history stored in memory.\n",
    "        \n",
    "        Returns:\n",
    "            str: The response generated by the language model.\n",
    "        \"\"\"\n",
    "        # Retrieve the current conversation history as a list of messages\n",
    "        conversation_history = self.memory.messages\n",
    "\n",
    "        # Predict the next response using the chain\n",
    "        response = self.chain.predict(\n",
    "            chat_history=conversation_history,\n",
    "            human_input=\"\"  # Empty because we are generating the AI's response\n",
    "        )\n",
    "\n",
    "        # Save the AI's response to the memory\n",
    "        self.memory.add_ai_message(response)\n",
    "        return response\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Adds a new message to the conversation history in memory.\n",
    "        \n",
    "        Args:\n",
    "            name (str): The name of the sender (usually \"Patient\" or \"Doctor\").\n",
    "            message (str): The content of the message.\n",
    "        \"\"\"\n",
    "        # Save the user input to the conversation memory\n",
    "        self.memory.add_user_message(message)\n",
    "    \n",
    "    def get_history(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the full conversation history stored in memory.\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: The list of messages in the conversation history.\n",
    "        \"\"\"\n",
    "        formatted_history = []\n",
    "        for msg in self.memory.messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                formatted_history.append(f\"User: {msg.content}\")\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                formatted_history.append(f\"AI: {msg.content}\")\n",
    "            else:\n",
    "                formatted_history.append(f\"System: {msg.content}\")\n",
    "        return formatted_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dialogue agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary Kong\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "User: My name is Gary Kong\n",
      "AI: Hello Gary! How can I assist you today regarding your heart failure?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary Kong\n",
      "AI: Hello Gary! How can I assist you today regarding your heart failure?\n",
      "Human: I am not feeling well\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "User: I am not feeling well\n",
      "AI: I'm sorry to hear that, Gary. It's important to monitor your symptoms closely and contact your healthcare provider for further evaluation and management. Take care of yourself and don't hesitate to seek medical attention if needed.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary Kong\n",
      "AI: Hello Gary! How can I assist you today regarding your heart failure?\n",
      "Human: I am not feeling well\n",
      "AI: I'm sorry to hear that, Gary. It's important to monitor your symptoms closely and contact your healthcare provider for further evaluation and management. Take care of yourself and don't hesitate to seek medical attention if needed.\n",
      "Human: Remind me what my name is\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "User: Remind me what my name is\n",
      "AI: Your name is Gary Kong. If you have any concerns about your health, please let me know so I can assist you further.\n",
      "\n",
      "\n",
      "Full Conversation History:\n",
      "User: My name is Gary Kong\n",
      "AI: Hello Gary! How can I assist you today regarding your heart failure?\n",
      "User: I am not feeling well\n",
      "AI: I'm sorry to hear that, Gary. It's important to monitor your symptoms closely and contact your healthcare provider for further evaluation and management. Take care of yourself and don't hesitate to seek medical attention if needed.\n",
      "User: Remind me what my name is\n",
      "AI: Your name is Gary Kong. If you have any concerns about your health, please let me know so I can assist you further.\n"
     ]
    }
   ],
   "source": [
    "# Test function for the DialogueAgent with full conversation export\n",
    "def test_dialogue_agent(\n",
    "        system_message = \"You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\",\n",
    "        messages = [\"My name is Gary Kong\", \"I am not feeling well\", \"Remind me what my name is\"]\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Tests the DialogueAgent acting as a doctor with a series of patient messages.\n",
    "    This can also be modified to make the agent act as a patient and the messages be doctor messages.\n",
    "\n",
    "    Args:\n",
    "        system_message (str): The initial system message for the agent\n",
    "        messages (List[str]): The list of messages to test the agent with\n",
    "    \"\"\"\n",
    "    # Set up the OpenAI model\n",
    "    model = ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo')\n",
    "    \n",
    "    # Create the DialogueAgent instance for the doctor\n",
    "    agent = DialogueAgent(\n",
    "        name=\"Doctor\",\n",
    "        system_message=system_message,\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    # Reset the conversation\n",
    "    agent.reset()\n",
    "        \n",
    "    # Simulate the conversation\n",
    "    for msg in messages:\n",
    "        # Doctor receives the patient's message\n",
    "        agent.receive(name=\"Patient\", message=msg)\n",
    "        \n",
    "        # Doctor sends a response\n",
    "        response = agent.send()\n",
    "        \n",
    "        # Print the response\n",
    "        print(f\"User: {msg}\")\n",
    "        print(f\"AI: {response}\\n\")\n",
    "\n",
    "    # Display the full conversation history\n",
    "    print(\"\\nFull Conversation History:\")\n",
    "    for message in agent.get_history():\n",
    "        print(message)\n",
    "\n",
    "# Run the test function\n",
    "test_dialogue_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent's Response: Hello Gary! How are you feeling today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary\n",
      "AI: Hello Gary! How are you feeling today?\n",
      "Human: Unwell\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent's Response: I'm sorry to hear that, Gary. Have you been experiencing any specific symptoms or changes in your condition recently?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary\n",
      "AI: Hello Gary! How are you feeling today?\n",
      "Human: Unwell\n",
      "AI: I'm sorry to hear that, Gary. Have you been experiencing any specific symptoms or changes in your condition recently?\n",
      "Human: Chest pain at the moment\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent's Response: I'm sorry to hear that you're experiencing chest pain, Gary. It's important to seek immediate medical attention for chest pain, especially if you have a history of heart failure. Please call emergency services or go to the nearest hospital right away. Take care.\n",
      "\n",
      "Full Conversation History:\n",
      "User: My name is Gary\n",
      "AI: Hello Gary! How are you feeling today?\n",
      "User: Unwell\n",
      "AI: I'm sorry to hear that, Gary. Have you been experiencing any specific symptoms or changes in your condition recently?\n",
      "User: Chest pain at the moment\n",
      "AI: I'm sorry to hear that you're experiencing chest pain, Gary. It's important to seek immediate medical attention for chest pain, especially if you have a history of heart failure. Please call emergency services or go to the nearest hospital right away. Take care.\n"
     ]
    }
   ],
   "source": [
    "# Integration and testing function\n",
    "def test_dialogue_with_user_interface(system_message = \"You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\"):\n",
    "    \"\"\"\n",
    "    This function simulates a conversation between a virtual doctor and a patient using a user interface, whereby the user can input messages acting as the patient.\n",
    "    This can also be modified to simulate a conversation whereby the agent acts as the patient and the user acts as the doctor.\n",
    "\n",
    "    Args:\n",
    "        system_message (str, optional): The system message for the agent. Defaults to \"You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\".\n",
    "    \"\"\"\n",
    "    # Set up the OpenAI model\n",
    "    model = ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo')\n",
    "    \n",
    "    # Create the DialogueAgent instance for the doctor\n",
    "    agent = DialogueAgent(\n",
    "        name=\"Dr. Alexis Wang\",\n",
    "        system_message=system_message,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # Create the UserInterface instance\n",
    "    ui = UserInterface(simulation_mode=False)  # Start in user input mode\n",
    "    \n",
    "    # Simulate the interaction\n",
    "    while True:\n",
    "        # Collect user input\n",
    "        user_input = ui.collect_user_input()\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            break  # Exit if in simulation mode or if input is None\n",
    "        \n",
    "        # Doctor agent receives the user's message\n",
    "        agent.receive(name=\"Patient\", message=user_input)\n",
    "        \n",
    "        # Doctor agent sends a response\n",
    "        response = agent.send()\n",
    "        \n",
    "        # Display the doctor's response\n",
    "        ui.display_response(response)\n",
    "    \n",
    "    # Display the full conversation history\n",
    "    print(\"\\nFull Conversation History:\")\n",
    "    for message in agent.get_history():\n",
    "        print(message)\n",
    "\n",
    "# Run the test function\n",
    "test_dialogue_with_user_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dialogue simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco-analysis-opEH7KmU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
