{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Setup\n",
    "\n",
    "This Jupyter notebook demonstrates the development of a virtual doctor chatbot that interacts with heart failure patients \n",
    "to monitor their progress. The chatbot uses LangChain and GPT-3.5 for natural language processing and response generation.\n",
    "\n",
    "Components:\n",
    "1. User Interface (UI): The primary interface for patient interaction.\n",
    "2. Conversational AI Core (GPT-3.5): Processes user input and generates responses.\n",
    "3. Dialogue Manager: Manages user sessions and ensures a logical conversation flow.\n",
    "4. Simulation Toggle: Allows switching between user interaction and simulated patient interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from typing import List, Callable\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from typing import List, Callable\n",
    "import os\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file\n",
    "ROOT_DIR = \".\"  # Set this to the root directory where your .env file is located\n",
    "load_dotenv(os.path.join(ROOT_DIR, \".env\"))\n",
    "\n",
    "# Set up unique ID for session\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "# Set environment variables for LangChain\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"HeartFailureMonitor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInterface:\n",
    "    def __init__(self, simulation_mode: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the User Interface with the given simulation mode.\n",
    "\n",
    "        Args:\n",
    "            simulation_mode (bool, optional): Whether to start in simulation mode. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.simulation_mode = simulation_mode  # By default, start in user input mode\n",
    "    \n",
    "    def set_simulation_mode(self, simulation_mode: bool):\n",
    "        \"\"\"\n",
    "        Set the simulation mode of the User Interface.\n",
    "\n",
    "        Args:\n",
    "            simulation_mode (bool): Whether to start in simulation mode.\n",
    "        \"\"\"\n",
    "        self.simulation_mode = simulation_mode\n",
    "        mode = \"Simulation Mode\" if self.simulation_mode else \"User Input Mode\"\n",
    "        print(f\"Mode toggled to: {mode}\")\n",
    "        \n",
    "    def collect_user_input(self):\n",
    "        \"\"\"\n",
    "        Collects user input.\n",
    "\n",
    "        Returns:\n",
    "            str: The user input.\n",
    "        \"\"\"\n",
    "        if not self.simulation_mode:\n",
    "            patient_input = input(\"Enter Patient Input. Enter 'exit' to stop chat: \")\n",
    "            return patient_input\n",
    "        else:\n",
    "            print(\"Simulation mode is ON. User input is disabled.\")\n",
    "            return None\n",
    "\n",
    "    def display_response(self, response: str):\n",
    "        \"\"\"\n",
    "        Displays the response to the user.\n",
    "\n",
    "        Args:\n",
    "            response (str): The response to display.\n",
    "        \"\"\"\n",
    "        print(f\"Doctor's Response: {response}\")\n",
    "\n",
    "# Initialize the UI\n",
    "ui = UserInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Dialogue Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(self, name: str, system_message: str, model: ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo')) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the DialogueAgent with a name, system message, and a language model.\n",
    "        \n",
    "        Args:\n",
    "            name (str): The name of the agent.\n",
    "            system_message (str): The initial system message to set the context.\n",
    "            model (ChatOpenAI): The language model to use for generating responses.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "\n",
    "        # Initialize chat message history to keep track of the entire conversation\n",
    "        self.memory = ChatMessageHistory()\n",
    "        \n",
    "        # Define the prompt template with placeholders\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                SystemMessage(content=self.system_message),  # The persistent system prompt\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),  # Where the memory will be stored.\n",
    "                HumanMessagePromptTemplate.from_template(\"{human_input}\"),  # Where the human input will be injected\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Define the LLM chain with the model, prompt, and memory\n",
    "        self.chain = LLMChain(\n",
    "            llm=self.model,\n",
    "            prompt=self.prompt,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Initialize the memory with the system message\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the conversation history in memory\n",
    "        \"\"\"\n",
    "        self.memory.clear()\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Generates a response based on the conversation history stored in memory.\n",
    "        \n",
    "        Returns:\n",
    "            str: The response generated by the language model.\n",
    "        \"\"\"\n",
    "        # Retrieve the current conversation history as a list of messages\n",
    "        conversation_history = self.memory.messages\n",
    "\n",
    "        # Predict the next response using the chain\n",
    "        response = self.chain.predict(\n",
    "            chat_history=conversation_history,\n",
    "            human_input=\"\"  # Empty because we are generating the AI's response\n",
    "        )\n",
    "\n",
    "        # Save the AI's response to the memory\n",
    "        self.memory.add_ai_message(response)\n",
    "        return response\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Adds a new message to the conversation history in memory.\n",
    "        \n",
    "        Args:\n",
    "            name (str): The name of the sender (usually \"Patient\" or \"Doctor\").\n",
    "            message (str): The content of the message.\n",
    "        \"\"\"\n",
    "        # Save the user input to the conversation memory\n",
    "        self.memory.add_user_message(message)\n",
    "    \n",
    "    def get_history(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the full conversation history stored in memory.\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: The list of messages in the conversation history.\n",
    "        \"\"\"\n",
    "        formatted_history = []\n",
    "        for msg in self.memory.messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                formatted_history.append(f\"Patient: {msg.content}\")\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                formatted_history.append(f\"Doctor: {msg.content}\")\n",
    "            else:\n",
    "                formatted_history.append(f\"System: {msg.content}\")\n",
    "        return formatted_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dialogue agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary Kong\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Patient: My name is Gary Kong\n",
      "Doctor's Response: Hello Gary! How are you feeling today?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: My name is Gary Kong\n",
      "AI: Hello Gary! How are you feeling today?\n",
      "Human: What is my name?\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Patient: What is my name?\n",
      "Doctor's Response: Your name is Gary Kong. How can I assist you today, Gary?\n",
      "\n",
      "Full Conversation History:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Patient: My name is Gary Kong',\n",
       " 'Doctor: Hello Gary! How are you feeling today?',\n",
       " 'Patient: What is my name?',\n",
       " 'Doctor: Your name is Gary Kong. How can I assist you today, Gary?']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function for the DialogueAgent with full conversation export\n",
    "def test_dialogue_agent(\n",
    "        system_message_doctor = \"You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\",\n",
    "        patient_messages = [\"My name is Gary Kong\", \"I am not feeling well\", \"Remind me what my name is\"]\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Tests the DialogueAgent with a series of patient messages.\n",
    "\n",
    "    Args:\n",
    "        system_message_doctor (str): The initial system message for the doctor.\n",
    "        patient_messages (List[str]): The list of patient messages to simulate.\n",
    "    \"\"\"\n",
    "    # Set up the OpenAI model\n",
    "    model = ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo')\n",
    "    \n",
    "    # Create the DialogueAgent instance for the doctor\n",
    "    doctor_agent = DialogueAgent(\n",
    "        name=\"Doctor\",\n",
    "        system_message=system_message_doctor,\n",
    "        model=model,\n",
    "    )\n",
    "    \n",
    "    # Reset the conversation\n",
    "    doctor_agent.reset()\n",
    "        \n",
    "    # Simulate the conversation\n",
    "    for msg in patient_messages:\n",
    "        # Doctor receives the patient's message\n",
    "        doctor_agent.receive(name=\"Patient\", message=msg)\n",
    "        \n",
    "        # Doctor sends a response\n",
    "        response = doctor_agent.send()\n",
    "        \n",
    "        # Print the response\n",
    "        print(f\"Patient: {msg}\")\n",
    "        print(f\"Doctor's Response: {response}\\n\")\n",
    "\n",
    "    # Display the full conversation history\n",
    "    print(\"\\nFull Conversation History:\")\n",
    "    for message in doctor_agent.get_history():\n",
    "        print(message)\n",
    "\n",
    "# Run the test function\n",
    "test_dialogue_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: my name is Gary\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Doctor's Response: Hello, Gary! How can I assist you today regarding your heart failure?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\n",
      "Human: my name is Gary\n",
      "AI: Hello, Gary! How can I assist you today regarding your heart failure?\n",
      "Human: can you just tell me what my name is, so that I know you work\n",
      "Human: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Doctor's Response: I apologize for the confusion. Your name is Gary. How can I help you today, Gary?\n",
      "Full Conversation History:\n",
      "Patient: my name is Gary\n",
      "Doctor: Hello, Gary! How can I assist you today regarding your heart failure?\n",
      "Patient: can you just tell me what my name is, so that I know you work\n",
      "Doctor: I apologize for the confusion. Your name is Gary. How can I help you today, Gary?\n"
     ]
    }
   ],
   "source": [
    "# Integration and testing function\n",
    "def test_dialogue_with_user_interface(system_message_doctor = \"You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\"):\n",
    "    \"\"\"\n",
    "    This function simulates a conversation between a virtual doctor and a patient using a user interface, whereby the user can input messages acting as the patient.\n",
    "\n",
    "    Args:\n",
    "        system_message_doctor (str, optional): The system message for the doctor. Defaults to \"You are Dr. Alexis Wang, a virtual doctor specialized in heart failure. Respond concisely and empathetically to patient updates.\".\n",
    "    \"\"\"\n",
    "    # Set up the OpenAI model\n",
    "    model = ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo')\n",
    "    \n",
    "    # Create the DialogueAgent instance for the doctor\n",
    "    doctor_agent = DialogueAgent(\n",
    "        name=\"Dr. Alexis Wang\",\n",
    "        system_message=system_message_doctor,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # Create the UserInterface instance\n",
    "    ui = UserInterface(simulation_mode=False)  # Start in user input mode\n",
    "    \n",
    "    # Simulate the interaction\n",
    "    while True:\n",
    "        # Collect user input\n",
    "        user_input = ui.collect_user_input()\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            break  # Exit if in simulation mode or if input is None\n",
    "        \n",
    "        # Doctor agent receives the user's message\n",
    "        doctor_agent.receive(name=\"Patient\", message=user_input)\n",
    "        \n",
    "        # Doctor agent sends a response\n",
    "        response = doctor_agent.send()\n",
    "        \n",
    "        # Display the doctor's response\n",
    "        ui.display_response(response)\n",
    "    \n",
    "    # Display the full conversation history\n",
    "    print(\"\\nFull Conversation History:\")\n",
    "    for message in doctor_agent.get_history():\n",
    "        print(message)\n",
    "\n",
    "# Run the test function\n",
    "test_dialogue_with_user_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dialogue simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco-analysis-opEH7KmU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
