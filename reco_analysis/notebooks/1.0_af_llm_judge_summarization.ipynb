{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0afb238",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09182ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f86a33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3842c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ChatOpenAI model instance\n",
    "model = ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo-1106')\n",
    "# model = ChatOpenAI(temperature=0.7, model_name='gpt-4-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e66caab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify patient transcript file to read in\n",
    "transcripts_version = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbb553",
   "metadata": {},
   "source": [
    "## System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38719a57-dd52-4123-a69b-409d3ae4bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system message for the evaluation\n",
    "system_message_summary_judge = \"\"\"\n",
    "System Message for Auto-Evaluation:\n",
    "\n",
    "You are tasked with evaluating a summary of a doctor-patient dialogue transcript based on predefined criteria. Your evaluation will consist of answering specific questions about the summary with Yes or No responses. However, your output should be 1 for Yes and 0 for No. Generate a CSV row with the appropriate 1 or 0 for each question in the order specified below.\n",
    "\n",
    "Instructions:\n",
    "- Carefully review the transcript and accompanying summary.\n",
    "- For each question, determine if the answer is Yes or No.\n",
    "- Output 1 for Yes and 0 for No.\n",
    "- Generate a single CSV row with your responses, maintaining the order of the questions as provided.\n",
    "\n",
    "Evaluation Criteria and CSV Column Names:\n",
    "\n",
    "2. Summary introduces patient by name and reports and reports their primary symptom(s)\n",
    "    - Does the summary introduce patient by name and report their primary symptom(s)? Don't write the name of the patient. Just 1 or 0 based on instruction\n",
    "3. Summary reports patient's current symptoms\n",
    "    - Does the summary reports the patient's current symptoms?\n",
    "4. Summary reports patient's vital signs\n",
    "    - Did the summary report the patient's vital signs?\n",
    "5. Summary reports patient's medications\n",
    "    - Did the summary report the patient's medications?\n",
    "6. Summary includes summarizing bullet points at the bottom that give an overview of the content of the transcript\n",
    "    - Does the summary include summarizing bullet points at the bottom that give an overview of the content of the transcript?\n",
    "7. No disagreement between symptoms in summary and symptoms in transcript\n",
    "    - Can you confirm that there is no disagreement between symptoms in the summary and symptoms in the transcript?\n",
    "8. No disagreement between vital signs in summary and vital signs in transcript\n",
    "    - Can you confirm that there is no disagreement between vital signs in the summary and vital signs in the transcript?\n",
    "9. No disagreement between meds in summary and meds in transcript\n",
    "    - Can you confirm that there is no disagreement between meds in the summary and meds in the transcript?\n",
    "10. Formatting of summary is consistent and appropriate\n",
    "    - Is the formatting of the summary consistent and appropriate?\n",
    "11. Language in summary is fitting for the audience (doctor)\n",
    "    - Is the language in the summary fitting for the audience (a doctor)?\n",
    "12. Summarization engine does not try to diagnose\n",
    "    - Can you confirm that the summary does include any attempt to diagnose?\n",
    "\n",
    "\n",
    "Please review the summary and transcript and provide a CSV row with 1 for Yes and 0 for No for each of the above criteria in the specified order.\n",
    "\n",
    "Here is the Summary, followed by the Transcript:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# took out this \n",
    "\n",
    "# 1. Transcript Number: \n",
    "#     -insert the Transcript Number here. this is located at the top of the prompt\n",
    "\n",
    "# 13. Any additional observations or suggestions for improvement?\n",
    "#     - Are there any additional observations or suggestions for improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99eea5",
   "metadata": {},
   "source": [
    "## Import Transcript & Summary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53e68902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "json_file_path = f\"../data/patients/patients_{transcripts_version}_with_transcripts.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    patients = json.load(json_file)\n",
    "\n",
    "# Specify the path to your summaries JSON file\n",
    "summaries_json_file_path = f\"../data/patients/patients_{transcripts_version}_summaries.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(summaries_json_file_path, 'r') as json_file:\n",
    "    summaries = json.load(json_file)\n",
    "\n",
    "# Specify the CSV file path (make sure it is a file, not a directory)\n",
    "csv_file_path = f\"../data/evaluations/summaries_{transcripts_version}_evaluation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfc8eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate and parse the response\n",
    "def parse_response(response_content, expected_fields=11):\n",
    "    response_list = response_content.split(',')\n",
    "\n",
    "    # Ensure the response has the expected number of fields\n",
    "    if len(response_list) < expected_fields:\n",
    "        # Handle the case where there are missing fields\n",
    "        response_list += [''] * (expected_fields - len(response_list))\n",
    "    elif len(response_list) > expected_fields:\n",
    "        # Handle the case where there are extra fields\n",
    "        response_list = response_list[:expected_fields]\n",
    "\n",
    "    # Function to validate and convert to int (0 or 1)\n",
    "    def validate_and_convert(value):\n",
    "        try:\n",
    "            # Convert to int and ensure it's either 0 or 1\n",
    "            int_value = int(value)\n",
    "            return int_value if int_value in [0, 1] else 0\n",
    "        except ValueError:\n",
    "            # Return 0 if conversion fails\n",
    "            return 0\n",
    "\n",
    "    # Apply validation and conversion to each field\n",
    "    response_list = [validate_and_convert(value.strip()) for value in response_list]\n",
    "\n",
    "    return response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ce17b16-8ed0-4d7f-873b-8fb316c3d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: ../data/evaluations/summaries_1.0_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "# Write the header to the CSV file\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    header = [\n",
    "        \"Transcript Number\",\n",
    "        \"Summary introduces patient by name and reports and reports their primary symptom(s)\",\n",
    "        \"Summary reports patient's current symptoms\",\n",
    "        \"Summary reports patient's vital signs\",\n",
    "        \"Summary reports patient's medications\",\n",
    "        \"Summary includes summarizing bullet points at the bottom that give an overview of the content of the transcript\",\n",
    "        \"No disagreement between symptoms in summary and symptoms in transcript\",\n",
    "        \"No disagreement between vital signs in summary and vital signs in transcript\",\n",
    "        \"No disagreement between meds in summary and meds in transcript\",\n",
    "        \"Formatting of summary is consistent and appropriate\",\n",
    "        \"Language in summary is fitting for the audience (doctor)\",\n",
    "        \"Summarization engine does not try to diagnose\"\n",
    "    ]\n",
    "\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Loop through each transcript number, invoke the model, and write the results\n",
    "    for transcript_number in patients.keys():\n",
    "        if transcript_number in patients:\n",
    "            transcript = patients[transcript_number]['chat_transcript']\n",
    "            summary = summaries[transcript_number]['summary']\n",
    "            full_prompt = f\"Transcript Number: {transcript_number}\\n\\n{system_message_summary_judge}\\n{summary}\\n{transcript}\"\n",
    "            # print(full_prompt)\n",
    "            # print(\"____________________________________\")\n",
    "            # Define the messages for the chat model\n",
    "            messages = [\n",
    "                SystemMessage(content=full_prompt),\n",
    "            ]\n",
    "            \n",
    "            # Get the response\n",
    "            response = model.invoke(messages)\n",
    "            response_content = response.content.strip()\n",
    "            \n",
    "            # Process the response to extract the CSV row\n",
    "            csv_row = parse_response(response_content)\n",
    "            csv_row.insert(0, transcript_number)  # Add transcript number as the first column\n",
    "            \n",
    "            # Write the CSV row to the file\n",
    "            csv_writer.writerow(csv_row)\n",
    "\n",
    "print(f\"CSV file has been created at: {csv_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
