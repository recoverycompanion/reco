{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0afb238",
   "metadata": {},
   "source": [
    "# LLM as a judge for Summarization Engine - version 1.1\n",
    "\n",
    "Some improvements to tackle:\n",
    "- have real evaluation (not just label everything as 1/good)\n",
    "- give some reasoning as to why the model is marking things as bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "09182ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3842c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ChatOpenAI model instance\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-0125\"  # release date: 2024-01-25\n",
    "# model_name = \"gpt-3.5-turbo-1106\"  # release date: 2023-11-06\n",
    "# model_name = \"gpt-4o-2024-05-13\"  # release date: 2024-05-13\n",
    "\n",
    "model = ChatOpenAI(temperature=0.0, model_name=model_name)\n",
    "\n",
    "### Specify patient transcript file to read in\n",
    "transcripts_version = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbb553",
   "metadata": {},
   "source": [
    "## System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "38719a57-dd52-4123-a69b-409d3ae4bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system message for the evaluation\n",
    "\n",
    "presence_description = \"Does the SUMMARY contain the presence of the patient's {topic}? It doesn't have to agree with TRANSCRIPT.\"\n",
    "\n",
    "judge_criteria = {\n",
    "    # summary content\n",
    "    \"intro_patient\": \"Does the SUMMARY introduce patient by name?\",\n",
    "    \"current_symptoms\": presence_description.format(topic=\"current symptoms\"),\n",
    "    \"vital_signs\": presence_description.format(topic=\"vital signs\"),\n",
    "    \"medications\": presence_description.format(topic=\"medications\"),\n",
    "    \"summary_overview\": \"Does the SUMMARY include an overview of the content of the TRANSCRIPT\",\n",
    "\n",
    "    # accuracy of summary\n",
    "    \"symptoms_agree\": \"Do the symptoms in the SUMMARY and TRANSCRIPT agree?\",\n",
    "    \"vital_signs_agree\": \"Do the vital signs in the SUMMARY and TRANSCRIPT agree?\",\n",
    "    \"meds_agree\": \"Do the meds in the SUMMARY and TRANSCRIPT agree?\",\n",
    "\n",
    "    # quality of summary\n",
    "    \"formatting\": \"Is the formatting of the SUMMARY consistent and appropriate?\",\n",
    "    # \"language_fitting\": \"Is the language in the SUMMARY fitting for the audience (doctors)?\",\n",
    "    \"no_diagnose\": \"The SUMMARY is free from interpretation of results (avoided words like 'stable') and is free from diagnosis. Narration of patient's words is allowed (like 'patient thinks that they have...').\",\n",
    "}\n",
    "\n",
    "system_message_summary_judge = \"\"\"You are evaluating a summarization engine that has generated a SUMMARY of a doctor-patient dialogue TRANSCRIPT based on a set of criteria. Your evaluation will consist of answering specific questions about the SUMMARY with 1 (Yes) and 0 (No) responses. The SUMMARY quality will depend on the TRANSCRIPT.\n",
    "{output_format}\n",
    "\n",
    "Criteria (CSV column names, then a description):\n",
    "\"\"\" + \"\\n\".join([f\"{k}, {v}\" for k, v in judge_criteria.items()])\n",
    "\n",
    "output_csv_format = \"\"\"Generate a CSV row with the appropriate 1 or 0 for each criteria in the order specified below.\"\"\"\n",
    "\n",
    "output_reasoning_format = \"\"\"In separate lines, state each criteria's value (1 or 0) and briefly explain your reasoning if it's a 0. For example:\n",
    "intro_patient,1,\"\"\n",
    "current_symptoms,0,\"Dyspnea was not mentioned in the summary\"\n",
    "\"\"\"\n",
    "\n",
    "human_message_summary_judge = \"\"\"\n",
    "TRANSCRIPT: {transcript}\n",
    "\n",
    "SUMMARY: {summary}\n",
    "\"\"\"\n",
    "\n",
    "# took out the following:\n",
    "# 13. Any additional observations or suggestions for improvement?\n",
    "#     - Are there any additional observations or suggestions for improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a52bf206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are evaluating a summarization engine that has generated a SUMMARY of a '\n",
      " 'doctor-patient dialogue TRANSCRIPT based on a set of criteria. Your '\n",
      " 'evaluation will consist of answering specific questions about the SUMMARY '\n",
      " 'with 1 (Yes) and 0 (No) responses. The SUMMARY quality will depend on the '\n",
      " 'TRANSCRIPT.\\n'\n",
      " '{output_format}\\n'\n",
      " '\\n'\n",
      " 'Criteria (CSV column names, then a description):\\n'\n",
      " 'intro_patient, Does the SUMMARY introduce patient by name?\\n'\n",
      " \"current_symptoms, Does the SUMMARY contain the presence of the patient's \"\n",
      " \"current symptoms? It doesn't have to agree with TRANSCRIPT.\\n\"\n",
      " \"vital_signs, Does the SUMMARY contain the presence of the patient's vital \"\n",
      " \"signs? It doesn't have to agree with TRANSCRIPT.\\n\"\n",
      " \"medications, Does the SUMMARY contain the presence of the patient's \"\n",
      " \"medications? It doesn't have to agree with TRANSCRIPT.\\n\"\n",
      " 'summary_overview, Does the SUMMARY include an overview of the content of the '\n",
      " 'TRANSCRIPT\\n'\n",
      " 'symptoms_agree, Do the symptoms in the SUMMARY and TRANSCRIPT agree?\\n'\n",
      " 'vital_signs_agree, Do the vital signs in the SUMMARY and TRANSCRIPT agree?\\n'\n",
      " 'meds_agree, Do the meds in the SUMMARY and TRANSCRIPT agree?\\n'\n",
      " 'formatting, Is the formatting of the SUMMARY consistent and appropriate?\\n'\n",
      " 'no_diagnose, The SUMMARY is free from interpretation of results (avoided '\n",
      " \"words like 'stable') and is free from diagnosis. Narration of patient's \"\n",
      " \"words is allowed (like 'patient thinks that they have...').\")\n"
     ]
    }
   ],
   "source": [
    "pprint(system_message_summary_judge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99eea5",
   "metadata": {},
   "source": [
    "## Import Transcript & Summary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "53e68902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "transcripts_json_file_path = f\"../data/patients/patients_{transcripts_version}_with_transcripts.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(transcripts_json_file_path, 'r') as json_file:\n",
    "    transcripts = json.load(json_file)\n",
    "\n",
    "# Specify the path to your summaries JSON file\n",
    "summaries_json_file_path = f\"../data/patients/patients_{transcripts_version}_summaries.json\"\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(summaries_json_file_path, 'r') as json_file:\n",
    "    summaries = json.load(json_file)\n",
    "\n",
    "# Specify the CSV file path (make sure it is a file, not a directory)\n",
    "csv_file_path = f\"../data/evaluations/summaries_{transcripts_version}_evaluation_2.csv\"\n",
    "\n",
    "# -----\n",
    "# for testing only; comment when not needed -- only try to generate one summary\n",
    "sample_patient_idx = 1\n",
    "transcripts = {k: v for k, v in transcripts.items() if k == list(transcripts.keys())[sample_patient_idx]}\n",
    "summaries = {k: v for k, v in summaries.items() if k == list(transcripts.keys())[0]}\n",
    "sole_patient_id = list(summaries.keys())[0]\n",
    "\n",
    "# tinker -- corrupt the summary to test the evaluator\n",
    "summaries[sole_patient_id][\"summary\"][\"Current Medications\"] = \"Furosemide and Spironolactone\"\n",
    "summaries[sole_patient_id][\"summary\"][\"Current Symptoms\"] += \"\\nNose bleeding\"\n",
    "summaries[sole_patient_id][\"summary\"][\"Vital Signs\"] = 'Temperature: 98.0 degrees\\nHeart Rate: 63 beats per minute\\nRespiratory Rate: 23 breaths per minute\\nOxygen Saturation: 94.0%\\nBlood Pressure: 123/56\\nWeight: N/A'\n",
    "summaries[sole_patient_id][\"summary\"][\"Summary\"] += \" Patient is unlikely to relapse.\"\n",
    "# -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dfc8eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate and parse the response\n",
    "\n",
    "# Example response\n",
    "#  'intro_patient,1,\"\"\\n'\n",
    "#  'current_symptoms,1,\"\"\\n'\n",
    "#  'symptoms_agree,0,\"Nose bleeding was mentioned in the summary, but not in the transcript.\"\\n'\n",
    "\n",
    "# Desired output\n",
    "# {\"intro_patient\": {\"value\": 1, \"reasoning\": \"\"}, \"current_symptoms\": {\"value\": 1, \"reasoning\": \"\"}, ...}\n",
    "\n",
    "def parse_response(response_content: str, expected_fields=len(judge_criteria)):\n",
    "    response_list = response_content.split(\"\\n\")\n",
    "    if len(response_list) != expected_fields:\n",
    "        return {\"error\": \"Invalid response count\"}\n",
    "    response_dict = {}\n",
    "    for response in response_list:\n",
    "        if response:\n",
    "            # split by first two commas, but keep the rest of the string\n",
    "            response_split = response.split(\",\", 2)\n",
    "            response_dict[response_split[0]] = {\"value\": int(response_split[1]), \"reasoning\": response_split[2].strip('\"')}\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5ce17b16-8ed0-4d7f-873b-8fb316c3d173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_number</th>\n",
       "      <th>intro_patient</th>\n",
       "      <th>intro_patient_reasoning</th>\n",
       "      <th>current_symptoms</th>\n",
       "      <th>current_symptoms_reasoning</th>\n",
       "      <th>vital_signs</th>\n",
       "      <th>vital_signs_reasoning</th>\n",
       "      <th>medications</th>\n",
       "      <th>medications_reasoning</th>\n",
       "      <th>summary_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>symptoms_agree</th>\n",
       "      <th>symptoms_agree_reasoning</th>\n",
       "      <th>vital_signs_agree</th>\n",
       "      <th>vital_signs_agree_reasoning</th>\n",
       "      <th>meds_agree</th>\n",
       "      <th>meds_agree_reasoning</th>\n",
       "      <th>formatting</th>\n",
       "      <th>formatting_reasoning</th>\n",
       "      <th>no_diagnose</th>\n",
       "      <th>no_diagnose_reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14185111</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Nose bleeding was not mentioned in the summary</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>The summary mentions fatigue which was not pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>The heart rate in the summary is 63 beats per ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The summary mentions Furosemide and Spironolac...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  transcript_number  intro_patient intro_patient_reasoning  current_symptoms  \\\n",
       "0          14185111              1                                         0   \n",
       "\n",
       "                       current_symptoms_reasoning  vital_signs  \\\n",
       "0  Nose bleeding was not mentioned in the summary            1   \n",
       "\n",
       "  vital_signs_reasoning  medications medications_reasoning  summary_overview  \\\n",
       "0                                  1                                       1   \n",
       "\n",
       "   ... symptoms_agree                           symptoms_agree_reasoning  \\\n",
       "0  ...              0  The summary mentions fatigue which was not pre...   \n",
       "\n",
       "  vital_signs_agree                        vital_signs_agree_reasoning  \\\n",
       "0                 0  The heart rate in the summary is 63 beats per ...   \n",
       "\n",
       "  meds_agree                               meds_agree_reasoning formatting  \\\n",
       "0          0  The summary mentions Furosemide and Spironolac...          1   \n",
       "\n",
       "   formatting_reasoning no_diagnose  no_diagnose_reasoning  \n",
       "0                                 1                         \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: ../data/evaluations/summaries_1.0_evaluation_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Write the header to dataframe\n",
    "# for each criteria, add two columns: one for the value (same name) and one for the reasoning (suffix _reasoning)\n",
    "column_order = [\"transcript_number\"]\n",
    "for criteria in judge_criteria.keys():\n",
    "    column_order.append(criteria)\n",
    "    column_order.append(f\"{criteria}_reasoning\")\n",
    "\n",
    "all_rows_series: list[pd.Series] = []\n",
    "# Loop through each transcript number, invoke the model, and write the results\n",
    "for patient_number in transcripts.keys():\n",
    "    if patient_number in transcripts:\n",
    "        transcript = transcripts[patient_number]['chat_transcript']\n",
    "        summary = summaries[patient_number]['summary']\n",
    "\n",
    "        prompt = (\n",
    "            SystemMessage(content=system_message_summary_judge.format(output_format=output_reasoning_format))\n",
    "            + human_message_summary_judge\n",
    "        )\n",
    "\n",
    "        # Get the response\n",
    "        response = model.invoke(prompt.format_messages(transcript=transcript, summary=summary))\n",
    "        response_dict = parse_response(response.content)\n",
    "\n",
    "        # add to dataframe\n",
    "        row_to_add = {\n",
    "            \"transcript_number\": patient_number,\n",
    "            **{k: v[\"value\"] for k, v in response_dict.items()},\n",
    "            **{f\"{k}_reasoning\": v[\"reasoning\"] for k, v in response_dict.items()},\n",
    "        }\n",
    "        all_rows_series.append(pd.Series(row_to_add))\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(all_rows_series)[column_order]\n",
    "\n",
    "display(df)\n",
    "\n",
    "# Write the dataframe to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "print(f\"CSV file has been created at: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b4ab7fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 148,\n",
       "  'prompt_tokens': 2177,\n",
       "  'total_tokens': 2325},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's an average response resource usage?\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ed127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(transcripts[sole_patient_id][\"chat_transcript\"])\n",
    "pprint(summaries[sole_patient_id][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "51d09559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_number</th>\n",
       "      <th>intro_patient</th>\n",
       "      <th>intro_patient_reasoning</th>\n",
       "      <th>current_symptoms</th>\n",
       "      <th>current_symptoms_reasoning</th>\n",
       "      <th>vital_signs</th>\n",
       "      <th>vital_signs_reasoning</th>\n",
       "      <th>medications</th>\n",
       "      <th>medications_reasoning</th>\n",
       "      <th>summary_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>symptoms_agree</th>\n",
       "      <th>symptoms_agree_reasoning</th>\n",
       "      <th>vital_signs_agree</th>\n",
       "      <th>vital_signs_agree_reasoning</th>\n",
       "      <th>meds_agree</th>\n",
       "      <th>meds_agree_reasoning</th>\n",
       "      <th>formatting</th>\n",
       "      <th>formatting_reasoning</th>\n",
       "      <th>no_diagnose</th>\n",
       "      <th>no_diagnose_reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14185111</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Nose bleeding was not mentioned in the summary</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>The summary mentions fatigue which was not pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>The heart rate in the summary is 63 beats per ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The summary mentions Furosemide and Spironolac...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   transcript_number  intro_patient  intro_patient_reasoning  \\\n",
       "0           14185111              1                      NaN   \n",
       "\n",
       "   current_symptoms                      current_symptoms_reasoning  \\\n",
       "0                 0  Nose bleeding was not mentioned in the summary   \n",
       "\n",
       "   vital_signs  vital_signs_reasoning  medications  medications_reasoning  \\\n",
       "0            1                    NaN            1                    NaN   \n",
       "\n",
       "   summary_overview  ...  symptoms_agree  \\\n",
       "0                 1  ...               0   \n",
       "\n",
       "                            symptoms_agree_reasoning vital_signs_agree  \\\n",
       "0  The summary mentions fatigue which was not pre...                 0   \n",
       "\n",
       "                         vital_signs_agree_reasoning meds_agree  \\\n",
       "0  The heart rate in the summary is 63 beats per ...          0   \n",
       "\n",
       "                                meds_agree_reasoning formatting  \\\n",
       "0  The summary mentions Furosemide and Spironolac...          1   \n",
       "\n",
       "   formatting_reasoning  no_diagnose  no_diagnose_reasoning  \n",
       "0                   NaN            1                    NaN  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# viewer: open the csv file as a pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
