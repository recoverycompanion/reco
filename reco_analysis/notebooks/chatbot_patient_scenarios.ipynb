{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot With Patient Personas\n",
    "\n",
    "This notebook provides a step-by-step guide for setting up and running simulated conversations between a virtual doctor and synthetic patients. The aim is to monitor the recovery of heart failure patients after they have been discharged from the hospital. The notebook is organized into the following sections:\n",
    "\n",
    "1. **Import and Setup**: Importing necessary libraries and setting up the environment.\n",
    "2. **Base Prompts**: Defining the system messages and AI guidance for both doctor and patient roles.\n",
    "3. **Functions**: Implementing functions for setting up the model, handling chat sessions,  defining the behavior of dialogue agents, simulating conversations and evaluating transcripts.\n",
    "4. **Baseline Conversations**: Running initial conversations to evaluate the performance of the virtual doctor.\n",
    "5. **Reluctant Patient Conversations**: Introducing a persona of a reluctant and evasive patient to test how the virtual doctor adapts.\n",
    "6. **Distracted Patient Conversations**: Introducing another persona of a tangential and distracted patient to further challenge the virtual doctor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-24 09:37:43.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreco_analysis.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple, Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import AIMessage, BaseChatMessageHistory, HumanMessage, SystemMessage\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from reco_analysis.synthetic_patients.create_patients import create_patients\n",
    "from reco_analysis.end_detector import extractor\n",
    "from reco_analysis.llm_judge.transcript_judge import TranscriptJudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../.env\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2307'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup timestamp extension for the output files\n",
    "def set_timestamp(timestamp = None) -> str:\n",
    "    \"\"\"\n",
    "    Sets the timestamp for the suffix of the output files. If manual is not provided, it will use the current date.\n",
    "\n",
    "    Args:\n",
    "        timestamp (str, optional): The timestamp to use. Should be in the format MMDD. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        str: The timestamp string\n",
    "    \"\"\"\n",
    "    if timestamp:\n",
    "        return str(timestamp)\n",
    "    else:\n",
    "        from datetime import datetime\n",
    "        return datetime.now().strftime(\"%d%m\")\n",
    "\n",
    "TIMESTAMP = set_timestamp(2307) # Insert a timestamp here if you want to manually set it so that the notebook reads the correct files\n",
    "TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base prompts\n",
    "Note: There are two types of system messages\n",
    "- system_message: Refers to the system message at the beginning of each chat\n",
    "- ai_guidance: Refers to additional instructions to the DialogueAgent that is provided after each run of the chat to guide the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Doctor Prompt\n",
    "system_message_doctor_base = \"\"\"\n",
    "You are a virtual doctor interacting with heart failure patients who have recently been discharged from the hospital. Your goal is to monitor their recovery by asking specific questions about their symptoms, vitals, and medications. Ensure the conversation is empathetic, providing clear information about their recovery process.\n",
    "\n",
    "When interacting with patients, inquire about the following topics in order:\n",
    "\n",
    "Topic 1: Introduction and Open-Ended Symptom Inquiry\n",
    "   - Greeting and Context: \"Hello, I'm here to check on how you're feeling today. Let's go over how you've been doing since your discharge.\"\n",
    "   - Open-Ended Question: \"Can you tell me how you've been feeling today? Have you noticed any new or worsening symptoms?\"\n",
    "\n",
    "Topic 2: Current Symptoms\n",
    "   - Follow-Up Questions:\n",
    "     - Dyspnea: \"Have you experienced any shortness of breath? If yes, does it occur at rest, when walking, or when climbing stairs?\"\n",
    "     - Paroxysmal Nocturnal Dyspnea (PND): \"Have you had sudden shortness of breath that wakes you up at night?\"\n",
    "     - Orthopnea: \"Do you need to prop yourself up with pillows to breathe comfortably while lying down?\"\n",
    "     - Edema: \"Have you noticed any swelling in your ankles or legs?\"\n",
    "     - Nocturnal Cough: \"Are you experiencing a cough, especially at night?\"\n",
    "     - Chest Pain: \"Have you had any chest pain recently?\"\n",
    "     - Fatigue and Mental Status: \"Do you feel more tired than usual or have you experienced any sudden changes in your mental clarity?\"\n",
    "\n",
    "Topic 3: Vital Signs\n",
    "   - Request Current Vitals: \"Could you please provide your latest vital signs? These include temperature, heart rate, respiratory rate, oxygen saturation, blood pressure, and weight.\"\n",
    "\n",
    "Topic 4: Current Medications\n",
    "   - Medication Inquiry: \"Let's review the medications you are currently taking. Are you on any of the following? Please confirm or list any other medications you are taking.\"\n",
    "     - ACE inhibitors (ACEi) : Lisinopril (Prinivil, Zestril), Enalapril (Vasotec), Ramipril (Altace)\n",
    "     - Angiotensin II Receptor Blockers (ARB) : Losartan (Cozaar), Valsartan (Diovan), Candesartan (Atacand)\n",
    "     - Angiotensin receptor/neprilysin inhibitor (ARNI) : Sacubitril/Valsartan (Entresto)\n",
    "     - Beta-Blockers (BB) : Carvedilol (Coreg), Metoprolol Succinate (Toprol XL), Bisoprolol (Zebeta)\n",
    "     - Thiazide diuretics:  Hydrochlorothiazide (Hydrodiuril), Chlorthalidone (Hygroton)\n",
    "     - Loop diuretics: Furosemide (Lasix), Torsemide (Demadex), Bumetanide (Bumex)\n",
    "     - Mineralocorticoid Receptor Antagonists (MRA) : Spironolactone (Aldactone), Eplerenone (Inspra)\n",
    "     - Hydralazine (Apresoline)\n",
    "     - Nitrate medications:  Isosorbide Mononitrate (Imdur), Isosorbide Dinitrate (Isordil)\n",
    "     - Ivabradine (Corlanor)\n",
    "     - SGLT2 inhibitors: Dapagliflozin (Farxiga), Empagliflozin (Jardiance)\n",
    "     - GLP-1 agonists: Liraglutide (Victoza), Semaglutide (Ozempic)\n",
    "\n",
    "Topic 5: Goodbye\n",
    "   - Thank the patient for their time, encourage them to continue monitoring their recovery closely, and say goodbye.\n",
    "\n",
    "Once you have covered a topic, do not revisit it unless the patient offers new information.\n",
    "\n",
    "Do not start a sentence with the word \"Doctor: \" or \"Patient :\".\n",
    "\n",
    "Throughout the conversation, maintain a patient-specific and empathetic tone:\n",
    "   - Recovery Overview: \"Based on your responses, here's an overview of where you are in your recovery and what you can expect in the coming days and weeks. It's important to continue monitoring your symptoms and adhering to your medication regimen.\"\n",
    "   - Empathy and Support: \"I'm sorry to hear you're experiencing [specific symptom]. It's important we address this to ensure your recovery continues smoothly. How can I further assist you today?\"\n",
    "   - Reminder: \"Please remember to contact your healthcare provider if you notice any significant changes or worsening of symptoms.\"\n",
    "\"\"\"\n",
    "\n",
    "ai_guidance_doctor_base = \"\"\"\n",
    "You are a doctor checking in with your patient. Review the conversation history to ensure you do not repeat any questions that were asked previously.\n",
    "Continue asking the patient questions until you have satisfied your inquiries about symptoms, vital signs, and medications. Only ask one simple question at a time.\n",
    "When asking for vital signs, ask for one at a time. If all your questions have been answered, end the conversation in a professional manner.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Patient Prompt\n",
    "system_message_patient_base = \"\"\"\n",
    "You are {name}, a patient who has been discharged after a hospital stay for heart failure. You are reporting your symptoms for a routine check-in with your doctor. Provide realistic, concise responses that would occur during an in-person clinical visit, ad-libbing personal details as needed to maintain realism, and keep responses to no more than two sentences. Include some filler words like 'um...' and 'ah...' to simulate natural conversation. Do not relay all information at once.\n",
    "\n",
    "Use the profile below during the conversation:\n",
    "<input>\n",
    "Gender: {gender}\n",
    "Age: {age}\n",
    "Race: {race}\n",
    "Marital status: {marital_status}\n",
    "Current symptoms: {chiefcomplaint}\n",
    "Current emotional state: {primary_patient_feeling}\n",
    "Current medications to report: {all_meds}\n",
    "Vital signs information:\n",
    "- Temperature: {vitals_temperature}\n",
    "- Heart rate: {vitals_heartrate}\n",
    "- Respiratory rate: {vitals_resprate}\n",
    "- O2 saturation: {vitals_o2sat}\n",
    "- Blood pressure: {vitals_sbp}/{vitals_dbp}\n",
    "- Weight: {weight} pounds\n",
    "- Pain: {vitals_pain}\n",
    "\n",
    "Do not start a sentence with the word \"Doctor: \" or \"Patient :\".\n",
    "\"\"\"\n",
    "\n",
    "ai_guidance_patient_base = \"\"\"\n",
    "Continue the role play in your role as a heart failure patient. Only answer the last question the doctor asked you. Feel free to embelish a little, but give simple, 1-2 sentence answers. Continue until the doctor ends the conversation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup default model for DialogueAgent()\n",
    "MODEL_DEFAULT = ChatOpenAI(temperature=0.7, model_name='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup In-memory Session Store\n",
    "session_store = {}\n",
    "\n",
    "def get_session_history(session_id: str, session_store: dict) -> BaseChatMessageHistory:\n",
    "    \"\"\"\n",
    "    Store the chat history for a given session ID.\n",
    "    \n",
    "    Args:\n",
    "        session_id (str): The session ID to retrieve the chat history for.\n",
    "        session_store (dict): The dictionary to store the chat histories.\n",
    "    \n",
    "    Returns:\n",
    "        BaseChatMessageHistory: The chat history for the session.\n",
    "    \"\"\"\n",
    "    if session_id not in session_store:\n",
    "        session_store[session_id] = ChatMessageHistory()\n",
    "    return session_store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInterface:\n",
    "    def __init__(self, agent_role='Doctor'):\n",
    "        \"\"\"\n",
    "        Initialize the User Interface\n",
    "\n",
    "        Args:\n",
    "            agent_role (str, optional): The role of the agent. Defaults to 'Doctor'.\n",
    "        \"\"\"\n",
    "        agent_role = agent_role.capitalize()\n",
    "        if agent_role not in ['Doctor', 'Patient']:\n",
    "            raise ValueError(\"Agent role must be either 'Doctor' or 'Patient'.\")\n",
    "        self.agent_role = agent_role\n",
    "            \n",
    "    def collect_user_input(self):\n",
    "        \"\"\"\n",
    "        Collects user input.\n",
    "\n",
    "        Returns:\n",
    "            str: The user input.\n",
    "        \"\"\"\n",
    "        user_input = input(\"Enter user message. Enter 'exit' to stop chat: \")\n",
    "        return user_input\n",
    "\n",
    "    def display_response(self, response: str):\n",
    "        \"\"\"\n",
    "        Displays the response to the user.\n",
    "\n",
    "        Args:\n",
    "            response (str): The response to display.\n",
    "        \"\"\"\n",
    "        print(f\"{self.agent_role}: {response}\")\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(self,\n",
    "                 role: Optional[str] = \"Doctor\",\n",
    "                 system_message: Optional[str] = system_message_doctor_base,\n",
    "                 ai_guidance: Optional[str] = ai_guidance_doctor_base,\n",
    "                 model: Optional[ChatOpenAI] = MODEL_DEFAULT,\n",
    "                 patient_id: Optional[str] = None,\n",
    "                 session_id: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the DialogueAgent with a name, system message, guidance after each run of the chat,\n",
    "        a language model, and a session ID.\n",
    "        \n",
    "        Args:\n",
    "            role (str): The role of the agent (either 'Patient' or 'Doctor').\n",
    "            system_message (str): The initial system message to set the context.\n",
    "            ai_guidance (str): The guidance for the AI after each run of the chat.\n",
    "            model (ChatOpenAI): The language model to use for generating responses.\n",
    "            patient_id (str, optional): The unique patient ID for the conversation. Defaults to None.\n",
    "            session_id (str, optional): The unique session ID for the conversation. Defaults to None. If None, a new session ID will be generated. If a session ID is provided, the conversation history will be loaded from the session store (if available)\n",
    "        \"\"\"\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "\n",
    "        # Set the patient ID\n",
    "        self.patient_id = patient_id\n",
    "\n",
    "        # Set the role of the agent and the human\n",
    "        role = role.capitalize()\n",
    "        if role not in [\"Patient\", \"Doctor\"]:\n",
    "            raise ValueError(\"Role must be either 'Patient' or 'Doctor'\")\n",
    "        self.role = role\n",
    "        self.human_role = \"Doctor\" if self.role == \"Patient\" else \"Patient\"\n",
    "\n",
    "        # Generate a unique conversation ID if one is not provided\n",
    "        self.session_id = str(uuid.uuid4()) if session_id is None else session_id\n",
    "\n",
    "        # Initialize chat message history to keep track of the entire conversation\n",
    "        self.memory = get_session_history(self.session_id, session_store)\n",
    "        \n",
    "        # Define the prompt template with placeholders for the chat history and human input\n",
    "        self.prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                SystemMessage(content=self.system_message),  # The persistent system prompt\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),  # Where the memory will be stored.\n",
    "                HumanMessagePromptTemplate.from_template(\"{human_input}\"),  # Where the human input will be injected\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Define the LLM chain with the model and prompt\n",
    "        self.chain = self.prompt | self.model | StrOutputParser()\n",
    "\n",
    "        # Prepare the AI instruction (this acts as guidance for the agent after each run of the chat)\n",
    "        self.ai_instruct = ai_guidance\n",
    "\n",
    "        # Initialize end of conversation flag\n",
    "        self.end_conversation = False\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Resets the conversation history in memory\n",
    "        \"\"\"\n",
    "        self.memory.clear()\n",
    "        self.end_conversation = False\n",
    "\n",
    "    def get_last_doctor_patient_messages(self) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Retrieves the last doctor and patient messages from the conversation history.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[str, str]: A tuple containing the last doctor and patient messages.\n",
    "        \"\"\"\n",
    "        last_doctor_message = None\n",
    "        last_patient_message = None\n",
    "\n",
    "        if len(self.memory.messages) >= 2 and self.memory.messages[-1].name == 'Patient' and self.memory.messages[-2].name == 'Doctor':\n",
    "            last_doctor_message = self.memory.messages[-2].content\n",
    "            last_patient_message = self.memory.messages[-1].content\n",
    "\n",
    "        return last_doctor_message, last_patient_message  \n",
    "    \n",
    "    def generate_response(self) -> str:\n",
    "        \"\"\"\n",
    "        Generates a response based on the conversation history stored in memory.\n",
    "        \n",
    "        Returns:\n",
    "            str: The response generated by the language model.\n",
    "        \"\"\"\n",
    "        # Prepare the input for the model\n",
    "        input_data = {\n",
    "            \"chat_history\": self.memory.messages,\n",
    "            \"human_input\": self.ai_instruct\n",
    "        }\n",
    "\n",
    "        # Run the chain to generate a response\n",
    "        response = self.chain.invoke(input_data)\n",
    "\n",
    "        # Save the AI's response to the memory\n",
    "        self.send(response)\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def send(self, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Adds a new message to the conversation history in memory for the AI role.\n",
    "\n",
    "        Args:\n",
    "            message (str): The content of the message.\n",
    "        \"\"\"\n",
    "        # Save the AI response to the conversation memory\n",
    "        self.memory.add_message(AIMessage(content=message, name=self.role))\n",
    "\n",
    "    def receive(self, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Adds a new message to the conversation history in memory for the human role.\n",
    "        \n",
    "        Args:\n",
    "            message (str): The content of the message.\n",
    "        \"\"\"\n",
    "        # Save the user input to the conversation memory\n",
    "        self.memory.add_message(HumanMessage(content=message, name=self.human_role))\n",
    "        \n",
    "    def get_history(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the full conversation history stored in memory.\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: The list of messages in the conversation history.\n",
    "        \"\"\"\n",
    "        formatted_history = []\n",
    "        for msg in self.memory.messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                formatted_history.append(f\"{self.human_role}: {msg.content}\")\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                formatted_history.append(f\"{self.role}: {msg.content}\")\n",
    "            else:\n",
    "                formatted_history.append(f\"System: {msg.content}\")\n",
    "        return formatted_history\n",
    "\n",
    "class DialogueSimulator():\n",
    "    def __init__(self, doctor_agent: DialogueAgent, patient_agent: DialogueAgent, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the DialogueSimulator with a list of agents and the starting agent.\n",
    "\n",
    "        Args:\n",
    "            doctor_agent (DialogueAgent): The doctor agent in the conversation.\n",
    "            patient_agent (DialogueAgent): The patient agent in the conversation.\n",
    "            verbose (bool): Whether to print the conversation steps. Defaults to False.\n",
    "        \"\"\"        \n",
    "        self.doctor_agent = doctor_agent\n",
    "        self.patient_agent = patient_agent\n",
    "        self.verbose = verbose\n",
    "                \n",
    "    def define_doctor_and_patient_indices(self) -> Tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Define the doctor and patient indices from the list of agents.\n",
    "        \"\"\"\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            if agent.role == \"Doctor\":\n",
    "                doctor_idx = i\n",
    "            elif agent.role == \"Patient\":\n",
    "                patient_idx = i\n",
    "        return doctor_idx, patient_idx\n",
    "    \n",
    "    def switch_agents(self) -> None:\n",
    "        \"\"\"\n",
    "        Switch the current agent between the doctor and the patient.\n",
    "        \"\"\"\n",
    "        self.current_agent = self.doctor_agent if self.current_agent == self.patient_agent else self.patient_agent\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Reset the conversation history for all agents in the simulation and sets the current agent to the starting agent.\n",
    "        \"\"\"\n",
    "        self.doctor_agent.reset()\n",
    "        self.patient_agent.reset()\n",
    "        self.current_agent = self.doctor_agent if self.starting_agent == \"Doctor\" else self.patient_agent\n",
    "\n",
    "    def initiate_conversation(self, starting_message: str) -> None:\n",
    "        \"\"\"\n",
    "        Initiate the conversation history with the starting message coming from the starting agent.\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "\n",
    "        speaker = self.doctor_agent if self.starting_agent == \"Doctor\" else self.patient_agent\n",
    "        receiver = self.patient_agent if self.starting_agent == \"Doctor\" else self.doctor_agent\n",
    "\n",
    "        speaker.send(starting_message)\n",
    "        if self.verbose:\n",
    "            print(f\"{speaker.role}: {starting_message}\")\n",
    "        receiver.receive(starting_message)\n",
    "\n",
    "        self.switch_agents()\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\"\n",
    "        Perform a single step in the conversation simulation by generating a response from the current agent.\n",
    "        \"\"\"\n",
    "        # Define the speaker and receiver\n",
    "        speaker = self.current_agent\n",
    "        receiver = self.doctor_agent if speaker == self.patient_agent else self.patient_agent\n",
    "\n",
    "        # Generate a response from the speaker\n",
    "        message = speaker.generate_response()\n",
    "        if self.verbose:\n",
    "            print(f\"{speaker.role}: {message}\")\n",
    "\n",
    "        # Receive the response from the speaker\n",
    "        receiver.receive(message)\n",
    "\n",
    "        # Switch the current agent\n",
    "        self.switch_agents()\n",
    "    \n",
    "    def run(self, num_steps: int, starting_agent: str, starting_message: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Run the conversation simulation for a given number of steps.\n",
    "\n",
    "        Args:\n",
    "            num_steps (int): The number of steps to run the simulation.\n",
    "            starting_message (str): The starting message to initiate the conversation.\n",
    "        \"\"\"\n",
    "        # Set the current agent to the starting agent\n",
    "        self.starting_agent = starting_agent.capitalize()\n",
    "        if self.starting_agent not in [\"Doctor\", \"Patient\"]:\n",
    "            raise ValueError(\"Starting agent must be either 'Doctor' or 'Patient'\")       \n",
    "        self.current_agent = self.doctor_agent if self.starting_agent == \"Doctor\" else self.patient_agent\n",
    "          \n",
    "        # Inject the initial message into the memory of the conversation\n",
    "        self.initiate_conversation(starting_message)\n",
    "\n",
    "        # Run the simulation for the specified number of steps\n",
    "        if self.verbose:\n",
    "            for _ in range(num_steps):\n",
    "                self.step()\n",
    "        else:\n",
    "            for _ in tqdm(range(num_steps), desc=\"Conversation Progress\", unit=\"step\"):\n",
    "                self.step()\n",
    "\n",
    "        # Get history from the starting agent\n",
    "        history = self.doctor_agent.get_history() if self.starting_agent == \"Doctor\" else self.patient_agent.get_history()\n",
    "        \n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Functions\n",
    "def test_dialogue_agent(system_message, ai_guidance, agent_role, user_messages):\n",
    "    \"\"\"\n",
    "    Tests the DialogueAgent acting as a doctor/patient with a series of patient/doctor messages.\n",
    "    This can also be modified to make the agent act as a patient and the user messages be doctor messages.\n",
    "\n",
    "    Args:\n",
    "        system_message (str): The initial system message for the agent\n",
    "        ai_guidance (str): The AI guidance message for the agent\n",
    "        agent_role (str): The role of the agent (either 'doctor' or 'patient')\n",
    "        user_messages (List[str]): The list of user messages to simulate the conversation\n",
    "        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n",
    "    \"\"\"\n",
    "    # Create the DialogueAgent instance for the doctor\n",
    "    agent = DialogueAgent(\n",
    "        role=agent_role,\n",
    "        patient_id = random.randint(1, 100),\n",
    "        system_message=system_message,\n",
    "        ai_guidance=ai_guidance,\n",
    "    )\n",
    "\n",
    "    # Define user and agent roles\n",
    "    agent_role = agent_role.capitalize()\n",
    "    user_role = \"Patient\" if agent_role == \"Doctor\" else \"Doctor\"\n",
    "        \n",
    "    # Simulate the conversation\n",
    "    for msg in user_messages:\n",
    "        # Print the response\n",
    "        print(f\"{user_role}: {msg}\")\n",
    "\n",
    "        # Doctor receives the patient's message\n",
    "        agent.receive(message=msg)\n",
    "\n",
    "        # Doctor sends a response\n",
    "        response = agent.generate_response()\n",
    "        \n",
    "        print(f\"{agent_role}: {response}\\n\")\n",
    "\n",
    "    # Get the full conversation history\n",
    "    history = agent.get_history()\n",
    "\n",
    "    return agent, history\n",
    "\n",
    "def test_dialogue_with_ui(system_message, ai_guidance, agent_role):\n",
    "    \"\"\"\n",
    "    This function simulates a conversation between a virtual doctor and a patient using a user interface, whereby the user can input messages acting as the patient or the doctor.\n",
    "    This can also be modified to simulate a conversation whereby the agent acts as the patient and the user acts as the doctor.\n",
    "\n",
    "    Args:\n",
    "        system_message (str): The initial system message for the agent\n",
    "        agent_role (str): The role of the agent (either 'doctor' or 'patient')\n",
    "    \"\"\"\n",
    "    # Create the DialogueAgent instance for the doctor\n",
    "    agent = DialogueAgent(\n",
    "        role=agent_role,\n",
    "        patient_id = random.randint(1, 100),\n",
    "        system_message=system_message,\n",
    "        ai_guidance=ai_guidance,\n",
    "    )\n",
    "\n",
    "    # Define user and agent roles\n",
    "    agent_role = agent_role.capitalize()\n",
    "    human_role = \"Patient\" if agent_role == \"Doctor\" else \"Doctor\"\n",
    "    \n",
    "    # Create the UserInterface instance\n",
    "    ui = UserInterface(agent_role=agent_role)\n",
    "    \n",
    "    # Simulate the interaction\n",
    "    while True:\n",
    "        # Collect user input\n",
    "        user_input = ui.collect_user_input()\n",
    "        print(f\"\\n{human_role}: {user_input}\")\n",
    "    \n",
    "        # Break if the user enters 'exit' or the conversation has ended\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        # Doctor agent receives the user's message\n",
    "        agent.receive(message=user_input)\n",
    "        \n",
    "        # Doctor agent sends a response\n",
    "        response = agent.generate_response()\n",
    "        \n",
    "        # Display the doctor's response\n",
    "        ui.display_response(response)\n",
    "    \n",
    "    # Get the full conversation history\n",
    "    history = agent.get_history()\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_single_conversation(\n",
    "        model_doctor: ChatOpenAI = MODEL_DEFAULT,\n",
    "        system_message_doctor:str=system_message_doctor_base,\n",
    "        ai_guidance_doctor:str=ai_guidance_doctor_base,\n",
    "        model_patient: ChatOpenAI = MODEL_DEFAULT,\n",
    "        system_message_patient:str=system_message_patient_base,\n",
    "        ai_guidance_patient:str=ai_guidance_patient_base,\n",
    "        num_steps:str=10,\n",
    "        starting_agent:str=\"Doctor\",\n",
    "        starting_message:str=\"Hello, I'm here to check on how you're feeling today. Let's go over how you've been doing since your discharge.\",\n",
    "        verbose:bool=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Test the DialogueSimulator by simulating a conversation between a doctor and a patient.\n",
    "\n",
    "    Args:\n",
    "        system_message_doctor (str): The system message for the doctor agent.\n",
    "        ai_guidance_doctor (str): The AI guidance for the doctor agent.\n",
    "        system_message_patient (str): The system message for the patient agent.\n",
    "        ai_guidance_patient (str): The AI guidance for the patient agent.\n",
    "        num_steps (int): The number of steps to run the simulation.\n",
    "        starting_agent (str): The starting agent for the conversation.\n",
    "        starting_message (str): The starting message to initiate the conversation.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The conversation history.\n",
    "        simulator: The DialogueSimulator instance.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create DialogueAgent instances for the doctor and patient\n",
    "    doctor_agent = DialogueAgent(role='Doctor', system_message=system_message_doctor, ai_guidance=ai_guidance_doctor, model=model_doctor)\n",
    "    patient_agent = DialogueAgent(role='Patient', system_message=system_message_patient, ai_guidance=ai_guidance_patient, model=model_patient)\n",
    "\n",
    "    simulator = DialogueSimulator(doctor_agent=doctor_agent, patient_agent=patient_agent, verbose=verbose)\n",
    "\n",
    "    # Run the dialogue simulation\n",
    "    conversation_history = simulator.run(\n",
    "        num_steps=num_steps,\n",
    "        starting_agent=starting_agent,\n",
    "        starting_message=starting_message,\n",
    "    )\n",
    "\n",
    "    # Return the conversation history\n",
    "    return conversation_history, simulator\n",
    "\n",
    "def simulate_multiple_conversations_and_save(\n",
    "    n_patients: int = 20, \n",
    "    model_doctor: ChatOpenAI = MODEL_DEFAULT,\n",
    "    ai_guidance_doctor: str = ai_guidance_doctor_base, \n",
    "    system_message_doctor: str = system_message_doctor_base,\n",
    "    model_patient: ChatOpenAI = MODEL_DEFAULT,\n",
    "    system_message_patient: str = system_message_patient_base, \n",
    "    ai_guidance_patient: str = ai_guidance_patient_base, \n",
    "    num_steps: int = 50, \n",
    "    starting_agent: str = \"Doctor\", \n",
    "    export_path: str = '',\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates synthetic patients, simulates dialogues for each patient, and saves the chat transcripts to a file.\n",
    "\n",
    "    Args:\n",
    "        n_patients (int): The number of patients to create and simulate dialogues for.\n",
    "        system_message_patient (str): The prompt text for patients.\n",
    "        system_message_doctor (str): The system message for the doctor agent.\n",
    "        ai_guidance_doctor (str): The AI guidance for the doctor agent.\n",
    "        ai_guidance_patient (str): The AI guidance for the patient agent.\n",
    "        num_steps (int): The number of steps to run the simulation.\n",
    "        starting_agent (str): The starting agent for the conversation.\n",
    "        starting_message (str): The starting message to initiate the conversation.\n",
    "        export_path (str): The file path to save the patient data with chat transcripts. Should be a .json file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The patient data, including the chat transcripts\n",
    "    \"\"\"\n",
    "    # Create patients\n",
    "    patients = create_patients(\n",
    "        n=n_patients,\n",
    "        prompt_text=system_message_patient\n",
    "    )\n",
    "\n",
    "    # Simulate dialogues for each patient\n",
    "    for idx, key in enumerate(patients.keys()):\n",
    "        print(f\"Simulating conversation {idx+1} out of {len(patients)}. Patient {patients[key]['id']}, {patients[key]['name']}\")\n",
    "        print(\"=\"*150)\n",
    "        convo, _ = simulate_single_conversation(\n",
    "            model_doctor=model_doctor,\n",
    "            system_message_doctor=system_message_doctor,\n",
    "            ai_guidance_doctor=ai_guidance_doctor,\n",
    "            model_patient=model_patient,\n",
    "            system_message_patient=patients[key]['prompt'],\n",
    "            ai_guidance_patient=ai_guidance_patient,\n",
    "            num_steps=num_steps,\n",
    "            starting_agent=starting_agent,\n",
    "            starting_message=f\"Hello {patients[key]['name']}, I'm here to check on how you're feeling today. Let's go over how you've been doing since your discharge.\",\n",
    "            verbose=verbose\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\"\\n\")\n",
    "\n",
    "        # Apply processing to the chat transcript to extract the first conversation\n",
    "        patients[key]['chat_transcript_full'] = convo\n",
    "        patients[key]['chat_transcript'] = extractor.process_transcript(convo, debug=verbose)\n",
    "        if verbose:\n",
    "            print(\"\\n\")\n",
    "\n",
    "    # Save the patient data with chat transcripts to a file\n",
    "    if export_path:\n",
    "        with open(export_path, 'w') as json_file:\n",
    "            json.dump(patients, json_file)\n",
    "        if verbose:\n",
    "            print(f\"Patient data with chat transcripts saved to {export_path}\")\n",
    "\n",
    "    return patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_for_eval(patients_dict: dict) -> List[Tuple[str, List[str], str]]:\n",
    "    \"\"\"\n",
    "    Prepares the synthetic patient data for evaluation by extracting the patient ID, chat transcript, and patient prompt.\n",
    "\n",
    "    Args:\n",
    "        patients_dict (dict): The dictionary containing the synthetic patient data.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, List[str], str]]: A list of tuples containing the patient ID, chat transcript, and patient prompt.\n",
    "    \"\"\"\n",
    "    patients_tuples = []\n",
    "    for key in patients_dict.keys():\n",
    "        patient = patients_dict[key]\n",
    "        patient_tuple = (patient['id'], patient['chat_transcript'], patient['prompt'])\n",
    "        patients_tuples.append(patient_tuple)\n",
    "    return patients_tuples\n",
    "\n",
    "def load_or_create_transcripts(file_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Load transcripts from a file if it exists, otherwise create and save them.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file containing the transcripts.\n",
    "        **create_kwargs: Arguments to pass to the create function if the file does not exist.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loaded or created transcripts.\n",
    "    \"\"\"\n",
    "    if file_path == '':\n",
    "        transcripts = simulate_multiple_conversations_and_save(**kwargs, export_path=file_path)\n",
    "    else:\n",
    "        if not os.path.exists(file_path):\n",
    "            transcripts = simulate_multiple_conversations_and_save(**kwargs, export_path=file_path)\n",
    "        else:\n",
    "            with open(file_path, 'r') as json_file:\n",
    "                transcripts = json.load(json_file)\n",
    "    return transcripts\n",
    "\n",
    "def load_or_create_transcripts(file_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Load transcripts from a file if it exists, otherwise create and save them.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file containing the transcripts.\n",
    "        **create_kwargs: Arguments to pass to the create function if the file does not exist.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loaded or created transcripts.\n",
    "    \"\"\"\n",
    "    if file_path == '':\n",
    "        transcripts = simulate_multiple_conversations_and_save(**kwargs, export_path=file_path)\n",
    "        print(f\"Transcripts created\")\n",
    "    elif not os.path.exists(file_path):\n",
    "        transcripts = simulate_multiple_conversations_and_save(**kwargs, export_path=file_path)\n",
    "        print(f\"Transcripts created and saved to {file_path}\")\n",
    "    else:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            transcripts = json.load(json_file)\n",
    "        print(f\"Transcripts loaded from {file_path}\")\n",
    "    return transcripts\n",
    "\n",
    "def load_or_create_evaluation(file_path, create_function, **kwargs):\n",
    "    \"\"\"\n",
    "    Load evaluation results from a file if it exists, otherwise create and save them.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file containing the evaluation results.\n",
    "        **create_kwargs: Arguments to pass to the create function if the file does not exist.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded or created evaluation results.\n",
    "    \"\"\"\n",
    "    if file_path == '':\n",
    "        evaluation = create_function(**kwargs)\n",
    "        print(f\"Evaluation results created\")\n",
    "    elif not os.path.exists(file_path):\n",
    "        evaluation = create_function(**kwargs)\n",
    "        evaluation.to_csv(file_path, index=False)\n",
    "        print(f\"Evaluation results created and saved to {file_path}\")\n",
    "    else:\n",
    "        evaluation = pd.read_csv(file_path)\n",
    "        print(f\"Evaluation results loaded from {file_path}\")\n",
    "    return evaluation\n",
    "\n",
    "def load_or_create_evaluation_improvements(file_path, create_function, **kwargs):\n",
    "    \"\"\"\n",
    "    Load evaluation improvements from a file if it exists, otherwise create and save them.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file containing the evaluation improvements.\n",
    "        **create_kwargs: Arguments to pass to the create function if the file does not exist.\n",
    "\n",
    "    Returns:\n",
    "        str: The loaded or created evaluation improvements.\n",
    "    \"\"\"\n",
    "    if file_path == '':\n",
    "        improvements = create_function(**kwargs)\n",
    "        print(f\"Evaluation improvements created\")\n",
    "    elif not os.path.exists(file_path):\n",
    "        improvements = create_function(**kwargs)\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(improvements)\n",
    "        print(f\"Evaluation improvements created and saved to {file_path}\")\n",
    "    else:\n",
    "        with open(file_path, 'r') as file:\n",
    "            improvements = file.read()\n",
    "        print(f\"Evaluation improvements loaded from {file_path}\")\n",
    "    return improvements\n",
    "\n",
    "def get_evaluation_scores(eval):\n",
    "    \"\"\"\n",
    "    Print the evaluation scores for each int64 column in the evaluation DataFrame.\n",
    "\n",
    "    Args:\n",
    "        eval (pd.DataFrame): The evaluation DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(\"===== Evaluation Scores =====\")\n",
    "    print(f\"Total number of transcripts evaluated: {len(eval)}\")\n",
    "    for col in eval.select_dtypes(include=['int64']).columns:\n",
    "        if col == 'transcript_number' or col == 'patient_name':\n",
    "            continue\n",
    "        print(f\"Score for {col}: {eval[col].sum()/len(eval)*100:.2f}%\")\n",
    "\n",
    "def print_observations(eval):\n",
    "    \"\"\"\n",
    "    Prints the observations by transcript number.\n",
    "    \n",
    "    Args:\n",
    "        eval (pd.DataFrame): The evaluation DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"===== Observations by Transcript Number =====\")\n",
    "    for number, line in zip(eval['transcript_number'], eval['observations']):\n",
    "        print(f\"{number}: {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper path_maker function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_maker(config_params: dict):\n",
    "    \"\"\"\n",
    "    Creates a path for saving or loading files based on the type of file and the model and prompt used.\n",
    "    \n",
    "    Args:\n",
    "        config_params: Dictionary containing configuration parameters.\n",
    "            - type (str): The type of file to create the path for. Can be one of 'transcripts', 'transcripts_eval', 'transcripts_eval_improvements', 'summaries', 'summaries_eval', 'summaries_eval_improvements'.\n",
    "            - termination (str): The type of transcript to create the path for. Can be either 'full' or 'short'. 'Full' is the full chat transcript, while 'short' is the extracted chat transcript.\n",
    "            - model_name (str): The name of the model used in the transcript. Can be one of '3.5', '4o-mini', '4o'.\n",
    "            - patient_prompt (str): The type of patient prompt used in the transcript. Can be one of 'base', 'reluctant', 'distracted'.\n",
    "            - doctor_prompt (str): The type of doctor prompt used in the transcript. Can be either 'base' or 'improved'.\n",
    "            - timestamp (str, optional): The timestamp for the file. Defaults to a global TIMESTAMP variable if not provided in the config dictionary.\n",
    "    Returns:\n",
    "        str: A formatted string representing the path for the specified file configuration.\n",
    "    \"\"\"\n",
    "    type = config_params['type']\n",
    "    termination = config_params['termination']\n",
    "    model_name = config_params['model_name']\n",
    "    patient_prompt = config_params['patient_prompt']\n",
    "    doctor_prompt = config_params['doctor_prompt']\n",
    "    timestamp = str(config_params.get('timestamp', TIMESTAMP))\n",
    "    \n",
    "    # Set the folder path depending on type\n",
    "    if type == 'transcripts':\n",
    "        folder_path = config.TRANSCRIPTS_DIR\n",
    "    elif type in ['transcripts_eval', 'transcripts_eval_improvements']:\n",
    "        folder_path = config.TRANSCRIPTS_EVALUATION_DIR\n",
    "    elif type == 'summaries':\n",
    "        folder_path = config.SUMMARIES_DIR\n",
    "    elif type in ['summaries_eval', 'summaries_eval_improvements']:\n",
    "        folder_path = config.SUMMARIES_EVALUATION_DIR\n",
    "\n",
    "    # Reformat fields\n",
    "    model_name = 'gpt' + model_name.replace('4o-mini', '4o-m')\n",
    "    patient_prompt = patient_prompt[:4] + 'pat'   \n",
    "    doctor_prompt = doctor_prompt[:4] + 'doc'\n",
    "\n",
    "    # Set to csv if this is an eval file\n",
    "    if type in ['transcripts_eval', 'summaries_eval']:\n",
    "        extension = 'csv'\n",
    "    else:\n",
    "        extension = 'json'\n",
    "\n",
    "    if timestamp:\n",
    "        return f\"{folder_path}/{type}_{termination}_{model_name}_{patient_prompt}_{doctor_prompt}_{timestamp}.{extension}\"\n",
    "    else:\n",
    "        return f\"{folder_path}/{type}_{termination}_{model_name}_{patient_prompt}_{doctor_prompt}.{extension}\"\n",
    "\n",
    "def compile_paths(\n",
    "        termination: Literal['full', 'short'],\n",
    "        model_name: Literal['3.5', '4o-mini', '4o'],\n",
    "        patient_prompt: Literal['base', 'reluctant', 'distracted'],\n",
    "        doctor_prompt: Literal['base', 'improved'],\n",
    "        timestamp = TIMESTAMP\n",
    "):\n",
    "    \"\"\"\n",
    "    Compiles the paths for the chat transcripts, evaluation, and evaluation improvements based on the configuration parameters.\n",
    "\n",
    "    Args:\n",
    "        termination (str): The type of transcript to create the path for. Can be either 'full' or 'short'. 'Full' is the full chat transcript, while 'short' is the extracted chat transcript.\n",
    "        model_name (str): The name of the model used in the transcript. Can be one of '3.5', '4o-mini', '4o'.\n",
    "        patient_prompt (str): The type of patient prompt used in the transcript. Can be one of 'base', 'reluctant', 'distracted'.\n",
    "        doctor_prompt (str): The type of doctor prompt used in the transcript. Can be either 'base' or 'improved'.\n",
    "        timestamp (str, optional): The timestamp for the file. Defaults to a global TIMESTAMP\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str, str]: A tuple containing the paths for the chat transcripts, evaluation, and evaluation improvements.\n",
    "    \"\"\"\n",
    "    # Compile the dictionary\n",
    "    config = {\n",
    "        'termination': termination,\n",
    "        'model_name': model_name,\n",
    "        'patient_prompt': patient_prompt,\n",
    "        'doctor_prompt': doctor_prompt,\n",
    "        'timestamp': str(timestamp)\n",
    "    }\n",
    "\n",
    "    # Create the paths\n",
    "    transcripts_path = path_maker({'type': 'transcripts', **config})\n",
    "    transcripts_eval_path = path_maker({'type': 'transcripts_eval', **config})\n",
    "    transcripts_eval_improvements_path = path_maker({'type': 'transcripts_eval_improvements', **config})\n",
    "\n",
    "    # Return tuple\n",
    "    return transcripts_path, transcripts_eval_path, transcripts_eval_improvements_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline HCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts 1\n",
    "- No natural termination\n",
    "- GPT 3.5-turbo\n",
    "- Baseline patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reco_analysis.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/transcripts/transcripts_full_gpt3.5_basepat_basedoc.json\n"
     ]
    }
   ],
   "source": [
    "TRANSCRIPTS_1_PATH, TRANSCRIPTS_EVAL_1_PATH, TRANSCRIPTS_EVAL_IMPROVEMENTS_1_PATH = compile_paths(\n",
    "    termination='full',\n",
    "    model_name='3.5',\n",
    "    patient_prompt='base',\n",
    "    doctor_prompt='base',\n",
    "    timestamp=''\n",
    ")\n",
    "\n",
    "print(TRANSCRIPTS_1_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/transcripts/transcripts_full_gpt3.5_basepat_basedoc.json\n"
     ]
    }
   ],
   "source": [
    "transcripts_1 = load_or_create_transcripts(\n",
    "    TRANSCRIPTS_1_PATH,\n",
    "    n_patients=20,\n",
    "    model_doctor=ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo'),\n",
    "    ai_guidance_doctor=ai_guidance_doctor_base,\n",
    "    system_message_doctor=system_message_doctor_base,\n",
    "    model_patient=ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo'),\n",
    "    system_message_patient=system_message_patient_base,\n",
    "    ai_guidance_patient=ai_guidance_patient_base,\n",
    "    num_steps=50,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_short_gpt3.5_basepat_basedoc_2307.csv\n",
      "Evaluation improvements loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_improvements_short_gpt3.5_basepat_basedoc_2307.json\n"
     ]
    }
   ],
   "source": [
    "judge_1 = TranscriptJudge()\n",
    "\n",
    "transcripts_1_eval = load_or_create_evaluation(\n",
    "    TRANSCRIPTS_1_EVAL_PATH,\n",
    "    judge_1.evaluate_batch,\n",
    "    entries = prep_data_for_eval(transcripts_1)\n",
    ")\n",
    "\n",
    "transcripts_1_eval_improvements = load_or_create_evaluation_improvements(\n",
    "    TRANSCRIPTS_1_EVAL_IMP_PATH,\n",
    "    judge_1.suggest_improvement,\n",
    "    original_chatbot_system_message_doctor=system_message_doctor_base,\n",
    "    original_chatbot_ai_guidance_doctor=ai_guidance_doctor_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts 2\n",
    "- Naturally terminated transcripts\n",
    "- GPT3.5-turbo\n",
    "- Baseline patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_2_PATH, TRANSCRIPTS_EVAL_2_PATH, TRANSCRIPTS_EVAL_IMPROVEMENTS_2_PATH = compile_paths(\n",
    "    termination='short',\n",
    "    model_name='3.5',\n",
    "    patient_prompt='base',\n",
    "    doctor_prompt='base',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/transcripts/transcripts_short_gpt3.5_basepat_basedoc_2307.json\n"
     ]
    }
   ],
   "source": [
    "transcripts_2 = load_or_create_transcripts(\n",
    "    TRANSCRIPTS_2_PATH,\n",
    "    n_patients=20,\n",
    "    model_doctor=ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo'),\n",
    "    ai_guidance_doctor=ai_guidance_doctor_base,\n",
    "    system_message_doctor=system_message_doctor_base,\n",
    "    model_patient=ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo'),\n",
    "    system_message_patient=system_message_patient_base,\n",
    "    ai_guidance_patient=ai_guidance_patient_base,\n",
    "    num_steps=50,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_short_gpt3.5_basepat_basedoc_2307.csv\n",
      "Evaluation improvements loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_improvements_short_gpt3.5_basepat_basedoc_2307.json\n",
      "===== Evaluation Scores =====\n",
      "Total number of transcripts evaluated: 20\n",
      "Score for dyspnea: 100.00%\n",
      "Score for pnd: 90.00%\n",
      "Score for orthopnea: 85.00%\n",
      "Score for nocturnal_cough: 75.00%\n",
      "Score for chest_pain: 85.00%\n",
      "Score for fatigue: 90.00%\n",
      "Score for worsening_mental_status: 80.00%\n",
      "Score for doctor_ask_medications: 100.00%\n",
      "Score for temperature: 100.00%\n",
      "Score for heart_rate: 100.00%\n",
      "Score for respiratory_rate: 100.00%\n",
      "Score for oxygen_saturation: 100.00%\n",
      "Score for blood_pressure: 90.00%\n",
      "Score for weight: 85.00%\n",
      "Score for sympathetic_patient: 100.00%\n",
      "Score for reminder: 80.00%\n",
      "Score for end_conversation: 90.00%\n",
      "Score for natural_conversation: 55.00%\n",
      "Score for no_premature_end: 95.00%\n",
      "Score for plain_language: 100.00%\n",
      "Score for consistent_symptoms: 100.00%\n",
      "Score for no_confabulations: 90.00%\n",
      "Score for allow_doctor_questions: 100.00%\n",
      "===== Observations by Transcript Number =====\n",
      "19597377: The DOCTOR should avoid repeating questions about vital signs and medications to maintain a more natural conversation flow.\n",
      "14206800: The conversation was thorough and covered all necessary aspects of the patient's condition and symptoms.\n",
      "17072793: The DOCTOR should ensure to ask about chest pain, fatigue, and nocturnal cough in future conversations.\n",
      "14584705: The conversation was thorough and covered all necessary aspects of the patient's condition and symptoms.\n",
      "16521649: The DOCTOR should ensure to ask for the PATIENT's blood pressure in future conversations.\n",
      "14717765: The DOCTOR should avoid repeating questions to ensure a more efficient and natural conversation flow.\n",
      "15343100: The DOCTOR should ensure to ask about nocturnal cough specifically in future conversations.\n",
      "13228928: The DOCTOR should ensure to ask about chest pain and nocturnal cough in future conversations.\n",
      "11922236: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen.\n",
      "15628804: The DOCTOR should ensure to ask about orthopnea, nocturnal cough, fatigue, worsening mental status, and the patient's weight in future conversations.\n",
      "11562514: The DOCTOR should ensure to ask for the PATIENT's weight and avoid repetitive segments to maintain a natural conversation flow.\n",
      "18056245: The DOCTOR should avoid repetitive questions and ensure a proper conclusion with reminders and expressions of care.\n",
      "12390274: The conversation was thorough and covered all necessary aspects of the patient's condition and symptoms.\n",
      "10816667: The DOCTOR should ensure to ask about orthopnea, nocturnal cough, chest pain, and worsening mental status, and provide reminders and encouragement at the end of the conversation.\n",
      "19380754: The DOCTOR should avoid repetitive greetings to maintain a more natural conversation flow.\n",
      "11532659: The DOCTOR should avoid repeating questions to ensure a more efficient and natural conversation flow.\n",
      "19557627: The DOCTOR should ensure to ask for all vital signs, including blood pressure and weight, to have a complete assessment.\n",
      "19291186: The conversation was thorough and covered all necessary aspects of the patient's condition and follow-up care.\n",
      "13423238: The PATIENT should ensure the accuracy of the medications they report to avoid inconsistencies.\n",
      "11052273: The DOCTOR should avoid repeating questions to ensure a more efficient and natural conversation flow.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline synthetic patient transcripts\n",
    "judge_2 = TranscriptJudge()\n",
    "\n",
    "# Load or create evaluation results for baseline patients\n",
    "transcripts_2_eval = load_or_create_evaluation(\n",
    "    TRANSCRIPTS_2_EVAL_PATH,\n",
    "    judge_2.evaluate_batch,\n",
    "    entries=prep_data_for_eval(transcripts_2)\n",
    ")\n",
    "\n",
    "transcripts_2_eval_imp = load_or_create_evaluation_improvements(\n",
    "    TRANSCRIPTS_2_EVAL_IMP_PATH,\n",
    "    judge_2.suggest_improvement,\n",
    "    original_chatbot_system_message_doctor=system_message_doctor_base,\n",
    "    original_chatbot_ai_guidance_doctor=ai_guidance_doctor_base\n",
    ")\n",
    "\n",
    "# Get evaluation scores for baseline patients\n",
    "get_evaluation_scores(transcripts_2_eval)\n",
    "\n",
    "# Print observations by transcript number\n",
    "print_observations(transcripts_2_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts 3\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o-mini\n",
    "- Baseline patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_3_PATH, TRANSCRIPTS_3_EVAL_PATH, TRANSCRIPTS_EVAL_IMP_3_PATH = compile_paths(\n",
    "    termination='short',\n",
    "    model_name='4o-mini',\n",
    "    patient_prompt='base',\n",
    "    doctor_prompt='base',\n",
    "    timestamp=TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/transcripts/transcripts_short_gpt4o-m_basepat_basedoc_2307.json\n"
     ]
    }
   ],
   "source": [
    "transcripts_3 = load_or_create_transcripts(\n",
    "    TRANSCRIPTS_3_PATH,\n",
    "    n_patients=20,\n",
    "    model_doctor=ChatOpenAI(temperature=0.7, model_name='gpt-4o-mini'),\n",
    "    ai_guidance_doctor=ai_guidance_doctor_base,\n",
    "    system_message_doctor=system_message_doctor_base,\n",
    "    model_patient=ChatOpenAI(temperature=0.7, model_name='gpt-4o-mini'),\n",
    "    system_message_patient=system_message_patient_base,\n",
    "    ai_guidance_patient=ai_guidance_patient_base,\n",
    "    num_steps=50,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_short_gpt4o-m_basepat_basedoc_2307.csv\n",
      "Evaluation improvements loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_improvements_short_gpt4o-m_basepat_basedoc_2307.json\n",
      "===== Evaluation Scores =====\n",
      "Total number of transcripts evaluated: 20\n",
      "Score for dyspnea: 100.00%\n",
      "Score for pnd: 100.00%\n",
      "Score for orthopnea: 85.00%\n",
      "Score for nocturnal_cough: 80.00%\n",
      "Score for chest_pain: 85.00%\n",
      "Score for fatigue: 70.00%\n",
      "Score for worsening_mental_status: 45.00%\n",
      "Score for doctor_ask_medications: 75.00%\n",
      "Score for temperature: 80.00%\n",
      "Score for heart_rate: 80.00%\n",
      "Score for respiratory_rate: 75.00%\n",
      "Score for oxygen_saturation: 75.00%\n",
      "Score for blood_pressure: 75.00%\n",
      "Score for weight: 75.00%\n",
      "Score for sympathetic_patient: 100.00%\n",
      "Score for reminder: 15.00%\n",
      "Score for end_conversation: 20.00%\n",
      "Score for natural_conversation: 90.00%\n",
      "Score for no_premature_end: 90.00%\n",
      "Score for plain_language: 100.00%\n",
      "Score for consistent_symptoms: 100.00%\n",
      "Score for no_confabulations: 100.00%\n",
      "Score for allow_doctor_questions: 100.00%\n",
      "===== Observations by Transcript Number =====\n",
      "11280189: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "14717765: The DOCTOR should remember to ask about fatigue and mental status changes, and provide reminders and encouragement at the end of the conversation.\n",
      "11477097: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "19818404: The DOCTOR should ensure to ask about the patient's medications and vital signs, and provide reminders and encouragement at the end of the conversation.\n",
      "19973319: The DOCTOR should ensure to ask about all vital signs and provide reminders for the PATIENT to contact their healthcare provider if symptoms worsen.\n",
      "12641479: The conversation was thorough and covered all necessary aspects of the patient's condition effectively.\n",
      "19124949: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "18435540: The DOCTOR should ensure to ask about chest pain, fatigue, mental status, medications, and vital signs, and provide reminders and encouragement at the end of the conversation.\n",
      "12246674: The DOCTOR should ensure to provide a proper closing to the conversation, including reminders and expressions of care.\n",
      "19516114: The DOCTOR should ensure to ask about orthopnea and worsening mental status, and provide reminders and encouragement at the end of the conversation.\n",
      "18080005: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen.\n",
      "10578325: The DOCTOR should avoid repetitive questions and ensure a proper conclusion with reminders for the PATIENT to contact their healthcare provider if needed.\n",
      "16883140: The DOCTOR should avoid repetitive questions and ensure to provide a proper closing statement with care and encouragement.\n",
      "18836076: The DOCTOR should consider asking about orthopnea and nocturnal cough to get a more comprehensive understanding of the patient's condition.\n",
      "17830851: The DOCTOR should ensure to ask about the patient's medications and vital signs to get a comprehensive understanding of the patient's current health status.\n",
      "15055518: The DOCTOR should ensure to ask about nocturnal cough, chest pain, fatigue, and worsening mental status, and provide reminders and encouragement at the end of the conversation.\n",
      "11080025: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "15389058: The DOCTOR should ensure to ask about fatigue and mental status changes, and provide reminders and encouragement at the end of the conversation.\n",
      "15714042: The DOCTOR should consider asking about orthopnea, nocturnal cough, and worsening mental status to provide a more comprehensive assessment.\n",
      "11052273: The DOCTOR should ensure to ask about chest pain, vital signs, and medications, and provide reminders and encouragement at the end of the conversation.\n"
     ]
    }
   ],
   "source": [
    "judge_3 = TranscriptJudge()\n",
    "\n",
    "transcripts_3_eval = load_or_create_evaluation(\n",
    "    TRANSCRIPTS_3_EVAL_PATH,\n",
    "    judge_3.evaluate_batch,\n",
    "    entries=prep_data_for_eval(transcripts_3)\n",
    ")\n",
    "\n",
    "transcripts_3_eval_imp = load_or_create_evaluation_improvements(\n",
    "    TRANSCRIPTS_3_EVAL_IMP_PATH,\n",
    "    judge_3.suggest_improvement,\n",
    "    original_chatbot_system_message_doctor=system_message_doctor_base,\n",
    "    original_chatbot_ai_guidance_doctor=ai_guidance_doctor_base\n",
    ")\n",
    "\n",
    "get_evaluation_scores(transcripts_3_eval)\n",
    "print_observations(transcripts_3_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts 4\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o\n",
    "- Baseline patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_4_PATH, TRANSCRIPTS_4_EVAL_PATH, TRANSCRIPTS_4_EVAL_IMP_PATH = compile_paths(\n",
    "    termination='short',\n",
    "    model_name='4o',\n",
    "    patient_prompt='base',\n",
    "    doctor_prompt='base',\n",
    "    timestamp=TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/transcripts/transcripts_short_gpt4o_basepat_basedoc_2307.json\n"
     ]
    }
   ],
   "source": [
    "transcripts_4 = load_or_create_transcripts(\n",
    "    TRANSCRIPTS_4_PATH,\n",
    "    n_patients=20,\n",
    "    model_doctor=ChatOpenAI(temperature=0.7, model_name='gpt-4o'),\n",
    "    ai_guidance_doctor=ai_guidance_doctor_base,\n",
    "    system_message_doctor=system_message_doctor_base,\n",
    "    model_patient=ChatOpenAI(temperature=0.7, model_name='gpt-4o'),\n",
    "    system_message_patient=system_message_patient_base,\n",
    "    ai_guidance_patient=ai_guidance_patient_base,\n",
    "    num_steps=50,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_short_gpt4o_basepat_basedoc_2307.csv\n",
      "Evaluation improvements loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_improvements_short_gpt4o_basepat_basedoc_2307.json\n",
      "===== Evaluation Scores =====\n",
      "Total number of transcripts evaluated: 20\n",
      "Score for dyspnea: 100.00%\n",
      "Score for pnd: 100.00%\n",
      "Score for orthopnea: 85.00%\n",
      "Score for nocturnal_cough: 80.00%\n",
      "Score for chest_pain: 85.00%\n",
      "Score for fatigue: 70.00%\n",
      "Score for worsening_mental_status: 45.00%\n",
      "Score for doctor_ask_medications: 75.00%\n",
      "Score for temperature: 80.00%\n",
      "Score for heart_rate: 80.00%\n",
      "Score for respiratory_rate: 75.00%\n",
      "Score for oxygen_saturation: 75.00%\n",
      "Score for blood_pressure: 75.00%\n",
      "Score for weight: 75.00%\n",
      "Score for sympathetic_patient: 100.00%\n",
      "Score for reminder: 15.00%\n",
      "Score for end_conversation: 20.00%\n",
      "Score for natural_conversation: 90.00%\n",
      "Score for no_premature_end: 90.00%\n",
      "Score for plain_language: 100.00%\n",
      "Score for consistent_symptoms: 100.00%\n",
      "Score for no_confabulations: 100.00%\n",
      "Score for allow_doctor_questions: 100.00%\n",
      "===== Observations by Transcript Number =====\n",
      "11280189: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "14717765: The DOCTOR should remember to ask about fatigue and mental status changes, and provide reminders and encouragement at the end of the conversation.\n",
      "11477097: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "19818404: The DOCTOR should ensure to ask about the patient's medications and vital signs, and provide reminders and encouragement at the end of the conversation.\n",
      "19973319: The DOCTOR should ensure to ask about all vital signs and provide reminders for the PATIENT to contact their healthcare provider if symptoms worsen.\n",
      "12641479: The conversation was thorough and covered all necessary aspects of the patient's condition effectively.\n",
      "19124949: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "18435540: The DOCTOR should ensure to ask about chest pain, fatigue, mental status, medications, and vital signs, and provide reminders and encouragement at the end of the conversation.\n",
      "12246674: The DOCTOR should ensure to provide a proper closing to the conversation, including reminders and expressions of care.\n",
      "19516114: The DOCTOR should ensure to ask about orthopnea and worsening mental status, and provide reminders and encouragement at the end of the conversation.\n",
      "18080005: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen.\n",
      "10578325: The DOCTOR should avoid repetitive questions and ensure a proper conclusion with reminders for the PATIENT to contact their healthcare provider if needed.\n",
      "16883140: The DOCTOR should avoid repetitive questions and ensure to provide a proper closing statement with care and encouragement.\n",
      "18836076: The DOCTOR should consider asking about orthopnea and nocturnal cough to get a more comprehensive understanding of the patient's condition.\n",
      "17830851: The DOCTOR should ensure to ask about the patient's medications and vital signs to get a comprehensive understanding of the patient's current health status.\n",
      "15055518: The DOCTOR should ensure to ask about nocturnal cough, chest pain, fatigue, and worsening mental status, and provide reminders and encouragement at the end of the conversation.\n",
      "11080025: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "15389058: The DOCTOR should ensure to ask about fatigue and mental status changes, and provide reminders and encouragement at the end of the conversation.\n",
      "15714042: The DOCTOR should consider asking about orthopnea, nocturnal cough, and worsening mental status to provide a more comprehensive assessment.\n",
      "11052273: The DOCTOR should ensure to ask about chest pain, vital signs, and medications, and provide reminders and encouragement at the end of the conversation.\n"
     ]
    }
   ],
   "source": [
    "judge_4 = TranscriptJudge()\n",
    "\n",
    "transcripts_4_eval = load_or_create_evaluation(\n",
    "    TRANSCRIPTS_4_EVAL_PATH,\n",
    "    judge_4.evaluate_batch,\n",
    "    entries=prep_data_for_eval(transcripts_4)\n",
    ")\n",
    "\n",
    "transcripts_4_eval_imp = load_or_create_evaluation_improvements(\n",
    "    TRANSCRIPTS_4_EVAL_IMP_PATH,\n",
    "    judge_4.suggest_improvement,\n",
    "    original_chatbot_system_message_doctor=system_message_doctor_base,\n",
    "    original_chatbot_ai_guidance_doctor=ai_guidance_doctor_base\n",
    ")\n",
    "\n",
    "get_evaluation_scores(transcripts_3_eval)\n",
    "print_observations(transcripts_3_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reluctant patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reluctant patient prompt\n",
    "system_message_patient_reluctant = \"\"\"\n",
    "You are {name}, a patient recently discharged after a hospital stay for heart failure. During a routine check-in with your doctor via chat, provide realistic responses while maintaining the following persona:\n",
    "\n",
    "<persona>\n",
    "**The Reluctant and Evasive Patient:**\n",
    "- Hesitates to share information and avoids answering direct questions.\n",
    "- Needs constant reassurance to provide details and frequently gives vague responses.\n",
    "- Expresses confusion when discussing medical terms or vital signs such as respiratory rate, heart rate, and O2 saturation.\n",
    "- Eventually provides the necessary, specific information when probed and reassured.\n",
    "- Uses a variety of hesitation phrases reflecting uncertainty, evasiveness or confusion. Examples of hesitation phrases include, but is not limited to:\n",
    "  **Uncertainty:**\n",
    "  - I dont remember exactly \n",
    "  - Its hard to say \n",
    "  - Maybe its\n",
    "\n",
    "  **Evasiveness:**\n",
    "  - Id rather not say\n",
    "  - I dont want to discuss that right now\n",
    "  - Is this really necessary?\n",
    "  - Can we talk about something else?\n",
    "\n",
    "  **Confusion:**\n",
    "  - I can't quite describe this (when asked about symptoms)\n",
    "  - Im not sure what youre asking\n",
    "  - I don't understand\n",
    "</persona>\n",
    "\n",
    "Chain of thought:\n",
    "<chain_of_thought>\n",
    "1. The doctor asks a question\n",
    "2. The patient hesitates and provides a vague or evasive response, not providing concrete figures or details (e.g., \"I'm pretty light, I think.\").\n",
    "3. If the doctor probes and reassure the patient, the patient eventually provides concrete figures and details (e.g., \"Oh right. I think I'm around 150 pounds.\").\n",
    "4. If the doctor does not probe and reassure the patient, the patient remains evasive or vague.\n",
    "</chain_of_thought>\n",
    "\n",
    "It is very important that you follow these guidelines during the conversation:\n",
    "<guidelines>\n",
    "- Never start a response with the word \"Patient: \" as you are the patient.\n",
    "- Use hesitation phrases sparingly and avoid repeating the same phrase too frequently.\n",
    "- Only use a maximum of one hesitation phrase per response.\n",
    "- Vary sentence structures, including where in the responses the hesitation phrase is placed.\n",
    "- Keep responses short, limited to two sentences at most, to maintain a conversational tone typical of a messaging chat.\n",
    "- Do not disclose all information at once; provide details gradually as the conversation progresses.\n",
    "</guidelines>\n",
    "\n",
    "\n",
    "Use the following example conversations as a guide:\n",
    "\n",
    "<example>\n",
    "Doctor: What is your current weight?\n",
    "Patient: I'm pretty light, I think.\n",
    "Doctor: Can you give me an estimate?\n",
    "Patient: Oh, right. I think I'm around 150 pounds.\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "Doctor: Can you tell me if you've experienced any shortness of breath?\n",
    "Patient: I don't understand what you mean.\n",
    "Doctor: Let me explain. Shortness of breath is when you feel like you can't get enough air. Have you felt that way?\n",
    "Patient: Oh, right. I've been feeling a bit out of breath lately.\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "Doctor: What is your current weight?\n",
    "Patient: It's pretty light, I think.\n",
    "Doctor: OK, thanks. Can you let me know what your temperature is?\n",
    "Patient: I don't know but I guess it's normal.\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "Doctor: Can you tell me if you've experienced any shortness of breath?\n",
    "Patient: I don't understand what you mean.\n",
    "Doctor: OK, let's move on. Have you been feeling tired or fatigued?\n",
    "Patient: Can't really say. I haven't been feeling great.\n",
    "</example>\n",
    "\n",
    "Use the below profile and vital signs during the conversation:\n",
    "<profile>\n",
    "Gender: {gender}\n",
    "Age: {age}\n",
    "Race: {race}\n",
    "Marital status: {marital_status}\n",
    "Current symptoms: {chiefcomplaint}\n",
    "Current emotional state: {primary_patient_feeling}\n",
    "Current medications: {all_meds}\n",
    "</profile>\n",
    "\n",
    "<vital_signs>\n",
    "Temperature: {vitals_temperature}F\n",
    "Heart rate: {vitals_heartrate} bpm\n",
    "Respiratory rate: {vitals_resprate} breaths/min\n",
    "O2 saturation: {vitals_o2sat}%\n",
    "Blood pressure: {vitals_sbp}/{vitals_dbp} mmHg\n",
    "Weight: {weight} pounds\n",
    "Pain level: {vitals_pain}/10\n",
    "</vital_signs>\n",
    "\"\"\"\n",
    "\n",
    "ai_guidance_patient_reluctant = \"\"\"\n",
    "Continue the role play as a heart failure patient in a chat, maintaining the persona of **The Reluctant and Evasive Patient**. Follow the guidelines, profile information and vital signs provided at the start. Enhance realism by ad-libbing personal details and embellishing as needed. Maintain this persona until the doctor ends the conversation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts 5\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o mini\n",
    "- Reluctant patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_5_PATH, TRANSCRIPTS_5_EVAL_PATH, TRANSCRIPTS_5_EVAL_IMP_PATH = compile_paths(\n",
    "    termination='short',\n",
    "    model_name='4o-mini',\n",
    "    patient_prompt='reluctant',\n",
    "    doctor_prompt='base',\n",
    "    timestamp=TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/transcripts/transcripts_short_gpt4o-m_relupat_basedoc_2307.json\n"
     ]
    }
   ],
   "source": [
    "transcripts_5 = load_or_create_transcripts(\n",
    "    TRANSCRIPTS_5_PATH,\n",
    "    n_patients=20,\n",
    "    model_doctor=ChatOpenAI(temperature=0.7, model_name='gpt-4o-mini'),\n",
    "    ai_guidance_doctor=ai_guidance_doctor_base,\n",
    "    system_message_doctor=system_message_doctor_base,\n",
    "    model_patient=ChatOpenAI(temperature=0.7, model_name='gpt-4o-mini'),\n",
    "    system_message_patient=system_message_patient_reluctant,\n",
    "    ai_guidance_patient=ai_guidance_patient_reluctant,\n",
    "    num_steps=50,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_short_gpt4o-m_relupat_basedoc_2307.csv\n",
      "Evaluation improvements loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_improvements_short_gpt4o-m_relupat_basedoc_2307.json\n",
      "===== Evaluation Scores =====\n",
      "Total number of transcripts evaluated: 20\n",
      "Score for dyspnea: 100.00%\n",
      "Score for pnd: 100.00%\n",
      "Score for orthopnea: 75.00%\n",
      "Score for nocturnal_cough: 95.00%\n",
      "Score for chest_pain: 95.00%\n",
      "Score for fatigue: 95.00%\n",
      "Score for worsening_mental_status: 95.00%\n",
      "Score for doctor_ask_medications: 95.00%\n",
      "Score for temperature: 90.00%\n",
      "Score for heart_rate: 95.00%\n",
      "Score for respiratory_rate: 90.00%\n",
      "Score for oxygen_saturation: 90.00%\n",
      "Score for blood_pressure: 95.00%\n",
      "Score for weight: 95.00%\n",
      "Score for sympathetic_patient: 100.00%\n",
      "Score for reminder: 0.00%\n",
      "Score for end_conversation: 0.00%\n",
      "Score for natural_conversation: 85.00%\n",
      "Score for no_premature_end: 100.00%\n",
      "Score for plain_language: 100.00%\n",
      "Score for consistent_symptoms: 100.00%\n",
      "Score for no_confabulations: 100.00%\n",
      "Score for allow_doctor_questions: 100.00%\n",
      "===== Observations by Transcript Number =====\n",
      "10112163: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "14108973: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "15393180: The DOCTOR should ensure to cover all relevant symptoms and vital signs, and provide reminders and encouragement at the end of the conversation.\n",
      "11169394: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "12007928: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "17133133: The DOCTOR should ensure to ask about orthopnea and remind the PATIENT to contact their healthcare provider if symptoms worsen, and also express care at the end of the conversation.\n",
      "15862920: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "15911683: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "15132645: The DOCTOR should ensure to remind the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "16633970: The DOCTOR should avoid repetitive questioning and ensure to provide a proper closing statement to the conversation.\n",
      "17333919: The DOCTOR should ensure to provide a reminder about contacting a healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "17659582: The DOCTOR should ensure to remind the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "11587903: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "12390274: The DOCTOR should ensure to provide a reminder about contacting healthcare providers for significant changes and avoid repetitive questioning to maintain a natural conversation flow.\n",
      "13743849: The DOCTOR should ensure to ask about respiratory rate and oxygen saturation, and provide a reminder to contact a healthcare provider if symptoms worsen.\n",
      "18417736: The DOCTOR should ensure to remind the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "10256360: The DOCTOR should ensure to remind the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "16252158: The DOCTOR should ensure to remind the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "17842643: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "11052273: The DOCTOR should ensure to remind the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n"
     ]
    }
   ],
   "source": [
    "judge_5 = TranscriptJudge()\n",
    "\n",
    "transcripts_5_eval = load_or_create_evaluation(\n",
    "    TRANSCRIPTS_5_EVAL_PATH,\n",
    "    judge_5.evaluate_batch,\n",
    "    entries=prep_data_for_eval(transcripts_5)\n",
    ")\n",
    "\n",
    "transcripts_5_eval_imp = load_or_create_evaluation_improvements(\n",
    "    TRANSCRIPTS_5_EVAL_IMP_PATH,\n",
    "    judge_5.suggest_improvement,\n",
    "    original_chatbot_system_message_doctor=system_message_doctor_base,\n",
    "    original_chatbot_ai_guidance_doctor=ai_guidance_doctor_base\n",
    ")\n",
    "\n",
    "get_evaluation_scores(transcripts_5_eval)\n",
    "\n",
    "print_observations(transcripts_5_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distracted patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reluctant patient prompt\n",
    "system_message_patient_distracted = \"\"\"\n",
    "You are {name}, a patient recently discharged after a hospital stay for heart failure. Your task is to engage in a realistic messaging chat with your doctor during a routine check-in. Follow the persona, guidelines, and examples below to structure your responses:\n",
    "\n",
    "<persona>\n",
    "**The Tangential Patient:**\n",
    "- Goes off on tangents and digresses from the main topic.\n",
    "- Does not provide the information requested in the initial response to a question from the doctor.\n",
    "- Provides the necessary information only if the doctor redirects the conversation back to the main topic and asks again for the specific information.\n",
    "- Struggles to maintain focus and may ask unrelated questions.\n",
    "- Follows one of these paths:\n",
    "  a. Doctor asks a question about topic A -&gt; Patient responds with an unrelated question/tangential story -&gt; Doctor redirects the conversation back to topic A -&gt; Patient provides the necessary information about topic A\n",
    "  b. Doctor asks a question about topic A -&gt; Patient responds with an unrelated question/tangential story -&gt; Doctor moves the conversation to topic B -&gt; Patient does not provide the necessary information about topic A\n",
    "  c. Doctor asks a question about topic A -&gt; Patient responds with an unrelated question/tangential story -&gt; Doctor does not redirect the conversation -&gt; Patient does not provide the necessary information about topic A\n",
    "</persona>\n",
    "\n",
    "Chain of thought:\n",
    "<chain_of_thought>\n",
    "1. The doctor asks a question (e.g., question A)\n",
    "2. Respond with an unrelated question or a tangential story, not answering the doctors question.\n",
    "3. If the doctor redirects back to the original question (i.e., question A), provide the necessary information in the next response.\n",
    "4. If the doctor does not redirect back to the original question (i.e., question A), or redirects to a different question, do not provide the necessary information\n",
    "</chain_of_thought>\n",
    "\n",
    "It is very important that you follow these guidelines during the conversation:\n",
    "<guidelines>\n",
    "- Never start a response with the word \"Patient: \" as you are the patient.\n",
    "- Avoid repetitive phrases like Oh, [Topic]! and use varied expressions instead.\n",
    "- Keep responses short, at two sentences maximum to maintain a conversational tone typical of a messaging chat.\n",
    "- Do not disclose all information at once; provide details gradually as the conversation progresses.\n",
    "</guidelines>\n",
    "\n",
    "Use the following example conversations as a guide:\n",
    "\n",
    "<example>\n",
    "Doctor: What is your current weight?\n",
    "Patient: Man, I've gained so much weight since the holidays. I can't believe how much I ate.\n",
    "Doctor: Yes the holidays can be a time for indulgence. Can you tell me your temperature?\n",
    "Patient: Speaking of which, it's been so cold lately. I can't believe how quickly the weather changed.\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "Doctor: Can you tell me if you've experienced any shortness of breath?\n",
    "Patient: What does shortness of breath indicate in heart failure, doc?\n",
    "Doctor: Shortness of breath can be a sign of fluid buildup in your lungs. Can you tell me if you've experienced chest pain?\n",
    "Patient: Oh, chest pain! That reminds me of a story about my friend's cat.\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "Doctor: What is your current weight?\n",
    "Patient: Man, I've gained so much weight since the holidays. I can't believe how much I ate.\n",
    "Doctor: Yes the holidays can be a time for indulgence. Can you tell me how much you weigh now?\n",
    "Patient: Oh, right. I think I'm around 150 pounds.\n",
    "</example>\n",
    "\n",
    "<example>\n",
    "Doctor: Can you tell me if you've experienced any shortness of breath?\n",
    "Patient: What does shortness of breath indicate in heart failure, doc?\n",
    "Doctor: Shortness of breath can be a sign of fluid buildup in your lungs. Back to the question, have you experienced any shortness of breath?\n",
    "Patient: Oh, right. I've been feeling a bit out of breath lately.\n",
    "</example>\n",
    "\n",
    "Use the below profile and vital signs during the conversation:\n",
    "<profile>\n",
    "Gender: {gender}\n",
    "Age: {age}\n",
    "Race: {race}\n",
    "Marital status: {marital_status}\n",
    "Current symptoms: {chiefcomplaint}\n",
    "Current emotional state: {primary_patient_feeling}\n",
    "Current medications: {all_meds}\n",
    "</profile>\n",
    "\n",
    "<vital_signs>\n",
    "Temperature: {vitals_temperature}F\n",
    "Heart rate: {vitals_heartrate} bpm\n",
    "Respiratory rate: {vitals_resprate} breaths/min\n",
    "O2 saturation: {vitals_o2sat}%\n",
    "Blood pressure: {vitals_sbp}/{vitals_dbp} mmHg\n",
    "Weight: {weight} pounds\n",
    "Pain level: {vitals_pain}/10\n",
    "</vital_signs>\n",
    "\"\"\"\n",
    "\n",
    "ai_guidance_patient_distracted = \"\"\"\n",
    "Continue the role play as a heart failure patient in a chat, maintaining the persona of **The Tangential Patient**. Follow the guidelines, and use the profile information and vital signs provided at the start. Enhance realism by ad-libbing personal details and embellishing as needed. Maintain this persona until the doctor ends the conversation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcripts 6\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o mini\n",
    "- Distracted patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_6_PATH, TRANSCRIPTS_6_EVAL_PATH, TRANSCRIPTS_6_EVAL_IMP_PATH = compile_paths(\n",
    "    termination='short',\n",
    "    model_name='4o-mini',\n",
    "    patient_prompt='distracted',\n",
    "    doctor_prompt='base',\n",
    "    timestamp=TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/transcripts/transcripts_short_gpt4o-m_distpat_basedoc_2307.json\n"
     ]
    }
   ],
   "source": [
    "transcripts_6 = load_or_create_transcripts(\n",
    "    TRANSCRIPTS_6_PATH,\n",
    "    n_patients=20,\n",
    "    model_doctor=ChatOpenAI(temperature=0.7, model_name='gpt-4o-mini'),\n",
    "    ai_guidance_doctor=ai_guidance_doctor_base,\n",
    "    system_message_doctor=system_message_doctor_base,\n",
    "    model_patient=ChatOpenAI(temperature=0.7, model_name='gpt-4o-mini'),\n",
    "    system_message_patient=system_message_patient_distracted,\n",
    "    ai_guidance_patient=ai_guidance_patient_distracted,\n",
    "    num_steps=50,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_short_gpt4o-m_distpat_basedoc_2307.csv\n",
      "Evaluation improvements loaded from /Users/garykong/Library/CloudStorage/GoogleDrive-garykong91@gmail.com/My Drive/Schoolwork/recoverycompanion/reco_analysis/data/evaluations/transcripts/transcripts_eval_improvements_short_gpt4o-m_distpat_basedoc_2307.json\n",
      "===== Evaluation Scores =====\n",
      "Total number of transcripts evaluated: 20\n",
      "Score for dyspnea: 100.00%\n",
      "Score for pnd: 100.00%\n",
      "Score for orthopnea: 100.00%\n",
      "Score for nocturnal_cough: 100.00%\n",
      "Score for chest_pain: 100.00%\n",
      "Score for fatigue: 100.00%\n",
      "Score for worsening_mental_status: 100.00%\n",
      "Score for doctor_ask_medications: 95.00%\n",
      "Score for temperature: 100.00%\n",
      "Score for heart_rate: 100.00%\n",
      "Score for respiratory_rate: 100.00%\n",
      "Score for oxygen_saturation: 100.00%\n",
      "Score for blood_pressure: 100.00%\n",
      "Score for weight: 100.00%\n",
      "Score for sympathetic_patient: 100.00%\n",
      "Score for reminder: 0.00%\n",
      "Score for end_conversation: 5.00%\n",
      "Score for natural_conversation: 100.00%\n",
      "Score for no_premature_end: 100.00%\n",
      "Score for plain_language: 100.00%\n",
      "Score for consistent_symptoms: 100.00%\n",
      "Score for no_confabulations: 100.00%\n",
      "Score for allow_doctor_questions: 100.00%\n",
      "===== Observations by Transcript Number =====\n",
      "17521224: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "17133133: The DOCTOR should ensure to provide a reminder about contacting a healthcare provider and express care at the end of the conversation.\n",
      "11642460: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "14856000: The DOCTOR should ensure to remind the PATIENT to contact their healthcare provider if they notice any significant changes or worsening of symptoms, and properly end the conversation with expressions of care and encouragement.\n",
      "14015736: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "14588689: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "19442084: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "17697993: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "18670109: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "12489621: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "19740429: The DOCTOR should ensure to provide a reminder about contacting a healthcare provider and express care at the end of the conversation.\n",
      "16114223: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "15049237: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "16883140: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "10816667: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "19380754: The DOCTOR should remember to ask about medications and provide reminders about contacting healthcare providers for any significant changes.\n",
      "12178737: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "10193065: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen and express care at the end of the conversation.\n",
      "19843520: The DOCTOR should include a reminder for the PATIENT to contact their healthcare provider if symptoms worsen.\n",
      "11052273: The DOCTOR should ensure to provide a reminder about contacting a healthcare provider for any significant changes and express care at the end of the conversation.\n"
     ]
    }
   ],
   "source": [
    "judge_6 = TranscriptJudge()\n",
    "\n",
    "transcripts_6_eval = load_or_create_evaluation(\n",
    "    TRANSCRIPTS_6_EVAL_PATH,\n",
    "    judge_6.evaluate_batch,\n",
    "    entries=prep_data_for_eval(transcripts_6)\n",
    ")\n",
    "\n",
    "transcripts_6_eval_imp = load_or_create_evaluation_improvements(\n",
    "    TRANSCRIPTS_6_EVAL_IMP_PATH,\n",
    "    judge_6.suggest_improvement,\n",
    "    original_chatbot_system_message_doctor=system_message_doctor_base,\n",
    "    original_chatbot_ai_guidance_doctor=ai_guidance_doctor_base\n",
    ")\n",
    "\n",
    "get_evaluation_scores(transcripts_6_eval)\n",
    "\n",
    "print_observations(transcripts_6_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco-analysis-opEH7KmU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
