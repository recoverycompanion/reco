{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Experiment Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates summaries for the transcripts generated in the chatbot_patient_scenarios notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-25 19:46:57.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mreco_analysis.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/anniefriar/Desktop/Berkeley/DATASCI_210/reco/reco_analysis\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import typing\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from PIL import Image as PILImage\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import Paragraph\n",
    "\n",
    "\n",
    "from reco_analysis.data_model import data_models\n",
    "from reco_analysis.summarizer_app import post_office, report_maker, summarizer_engine, data_type\n",
    "from reco_analysis.summarizer_app.prompts import system_message_summarize_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../.env\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model = ChatOpenAI(temperature=0.0, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_path = f\"../docs/reco_logo.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up and Test Summary & PDF Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(\n",
    "    patient_transcript: list[str],\n",
    "    model: ChatOpenAI = default_model,\n",
    "    system_prompt: str = system_message_summarize_json,\n",
    ") -> typing.Tuple[data_type.TranscriptSummary, BaseMessage]:\n",
    "    \"\"\"Summarizes a patient transcript.\n",
    "\n",
    "    Args:\n",
    "        patient_transcript (list[str]): The patient transcript to summarize.\n",
    "        model (ChatOpenAI, optional): The model to use for summarization.\n",
    "            Defaults to default_model.\n",
    "        system_prompt (str, optional): The system prompt to use.\n",
    "    \"\"\"\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", \"\\n\".join(patient_transcript)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = model.invoke(prompt_template.format_messages())\n",
    "    result_summary = response.content\n",
    "\n",
    "    try:\n",
    "        # Process the result, remove markdown and convert to JSON\n",
    "        processed_result = json.loads(\n",
    "            result_summary.replace(\"```json\", \"\").replace(\"```\", \"\").replace(\"\\n\", \"\")\n",
    "        )\n",
    "        vitals: typing.Dict[str, typing.Any] = processed_result[\"vital_signs\"]\n",
    "\n",
    "        def get_vital(vital_name: str) -> typing.Any:\n",
    "            ret = vitals.get(vital_name, None)\n",
    "            if not isinstance(ret, (int, float)):\n",
    "                return None\n",
    "            return ret\n",
    "\n",
    "        return (\n",
    "            data_type.TranscriptSummary(\n",
    "                patient_overview=processed_result[\"patient_overview\"],\n",
    "                current_symptoms=processed_result[\"current_symptoms\"],\n",
    "                vital_signs=data_type.VitalSigns(\n",
    "                    temperature=get_vital(\"temperature\"),\n",
    "                    heart_rate=get_vital(\"heart_rate\"),\n",
    "                    respiratory_rate=get_vital(\"respiratory_rate\"),\n",
    "                    oxygen_saturation=get_vital(\"oxygen_saturation\"),\n",
    "                    blood_pressure_systolic=get_vital(\"blood_pressure_systolic\"),\n",
    "                    blood_pressure_diastolic=get_vital(\"blood_pressure_diastolic\"),\n",
    "                    weight=get_vital(\"weight\"),\n",
    "                ),\n",
    "                current_medications=processed_result[\"current_medications\"],\n",
    "                summary=processed_result[\"summary\"],\n",
    "            ),\n",
    "            response,\n",
    "        )\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(\"Failed to decode JSON from model output\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patient_report(\n",
    "    summary_data: data_type.TranscriptSummary,\n",
    "    transcript: list[str],\n",
    "    output_filename: str | None = None,\n",
    ") -> bytes:\n",
    "    \"\"\"Create a PDF report summarizing the patient's conversation with the virtual doctor.\n",
    "\n",
    "    Args:\n",
    "        summary_data (data_type.TranscriptSummary): The summary data of the patient's conversation.\n",
    "        transcript (list[str]): The transcript of the patient's conversation.\n",
    "        output_filename (str): The output filename for the PDF report.\n",
    "\n",
    "    Returns:\n",
    "        A file object of the PDF report.\n",
    "    \"\"\"\n",
    "    c = canvas.Canvas(output_filename, pagesize=letter)\n",
    "\n",
    "    logo = PILImage.open(logo_path)\n",
    "    img_width, img_height = logo.size\n",
    "\n",
    "    first_comma_pos = transcript[0].find(\",\")\n",
    "    patient_name = transcript[0][14:first_comma_pos]\n",
    "    patient_first_name = patient_name.split(\" \")[0]\n",
    "    patient_last_name = patient_name.split(\" \")[1]\n",
    "\n",
    "    # Set font styles\n",
    "    title_style = \"Helvetica-Bold\"\n",
    "    section_title_style = \"Helvetica-Bold\"\n",
    "    section_content_style = \"Helvetica\"\n",
    "\n",
    "    # Draw logo and title\n",
    "    title = \"RECO Patient Report\"\n",
    "    c.setFont(title_style, 18)\n",
    "    c.drawImage(logo_path, 50, 720, width=img_width / 4, height=img_height / 4)\n",
    "    c.drawString(88, 727, title)\n",
    "    c.line(50, 710, 550, 710)  # Draw a line under the title\n",
    "\n",
    "    # Draw patient name and conversation date\n",
    "    c.setFont(section_content_style, 11)\n",
    "    c.drawString(50, 695, f\"Patient: {patient_first_name}, {patient_last_name.upper()}\")\n",
    "    c.drawString(\n",
    "        50,\n",
    "        680,\n",
    "        f\"\", # Removed conversation date for batch jobs\n",
    "    )\n",
    "\n",
    "    # Vertical position for content\n",
    "    y_position = 665\n",
    "\n",
    "    # Define paragraph styles\n",
    "    styles = getSampleStyleSheet()\n",
    "    body_style = styles[\"Normal\"]\n",
    "    body_style.fontName = \"Helvetica\"\n",
    "    body_style.fontSize = 11\n",
    "    body_style.leading = 14\n",
    "\n",
    "    bulleted_body_style = copy.deepcopy(body_style)\n",
    "    bulleted_body_style.leftIndent = 10\n",
    "\n",
    "    def start_new_page_if_needed(new_height):\n",
    "        \"\"\"Check if the line will fit on the current page, if not, start a new page\"\"\"\n",
    "        nonlocal y_position\n",
    "        if y_position - new_height < 50:\n",
    "            c.showPage()\n",
    "            y_position = letter[1] - 50\n",
    "\n",
    "    vitals_lines = \"\\n\".join(\n",
    "        [\n",
    "            f\"Temperature: {summary_data.vital_signs.temperature or 'N/A'} Â°F\",\n",
    "            f\"Heart Rate: {summary_data.vital_signs.heart_rate or 'N/A'} bpm\",\n",
    "            f\"Respiratory Rate: {summary_data.vital_signs.respiratory_rate or 'N/A'} bpm\",\n",
    "            f\"Oxygen Saturation: {summary_data.vital_signs.oxygen_saturation or 'N/A'} %\",\n",
    "            (\n",
    "                \"Blood Pressure: \"\n",
    "                + (\n",
    "                    f\"{summary_data.vital_signs.blood_pressure_systolic}/{summary_data.vital_signs.blood_pressure_diastolic}\"\n",
    "                    if summary_data.vital_signs.blood_pressure_systolic\n",
    "                    and summary_data.vital_signs.blood_pressure_diastolic\n",
    "                    else \"N/A\"\n",
    "                )\n",
    "            ),\n",
    "            f\"Weight: {summary_data.vital_signs.weight or 'N/A'} lbs\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Iterate through the sections and draw each section\n",
    "    for key, value in [\n",
    "        (\"Patient Overview\", summary_data.patient_overview),\n",
    "        (\"Current Symptoms\", summary_data.current_symptoms),\n",
    "        (\"Vital Signs\", vitals_lines),\n",
    "        (\"Current Medications\", summary_data.current_medications),\n",
    "        (\"Summary\", summary_data.summary),\n",
    "    ]:\n",
    "        value = copy.deepcopy(value)\n",
    "\n",
    "        # Section title\n",
    "        c.setFont(section_title_style, 12)\n",
    "        y_position -= 20  # Move down 20 units\n",
    "        c.drawString(50, y_position, key.upper())\n",
    "\n",
    "        # Section content\n",
    "        c.setFont(section_content_style, 11)\n",
    "        y_position -= 20  # Move down another 20 units for content\n",
    "\n",
    "        if isinstance(value, str):  # patient overview, summary\n",
    "            summary_text = value.replace(\"\\n\", \"<br/>\")  # Replace newlines with HTML line breaks\n",
    "\n",
    "            if summary_text[-1] != \".\":\n",
    "                summary_text = summary_text + \".\"\n",
    "\n",
    "            summary_paragraph = Paragraph(summary_text, body_style)\n",
    "\n",
    "            width, height = summary_paragraph.wrap(500, 800)\n",
    "            start_new_page_if_needed(height)\n",
    "            summary_paragraph.drawOn(c, 50, y_position - height + 10)\n",
    "            y_position -= height  # Add extra space after the paragraph\n",
    "\n",
    "        elif isinstance(value, list):  # current symptoms, current medications\n",
    "            for line in value:\n",
    "                bulleted_paragraph = Paragraph(line, bulleted_body_style, bulletText=\"â¢\")\n",
    "                width, height = bulleted_paragraph.wrap(500, 800)\n",
    "                start_new_page_if_needed(height)\n",
    "                bulleted_paragraph.drawOn(c, 50, y_position - height + 10)\n",
    "                y_position -= height\n",
    "\n",
    "    # Add the transcript to the end of the file\n",
    "    c.showPage()  # Start a new page\n",
    "    y_position = letter[1] - 50  # Reset y position for new page\n",
    "\n",
    "    section_title = \"Transcript\"\n",
    "    c.setFont(section_title_style, 12)\n",
    "    y_position -= 20  # Move down 20 units\n",
    "    c.drawString(50, y_position, section_title.upper())\n",
    "\n",
    "    # Section content\n",
    "    c.setFont(section_content_style, 11)\n",
    "    y_position -= 20  # Move down another 20 units for content\n",
    "\n",
    "    for transcript_line in transcript:\n",
    "        # Create a paragraph with the summary text\n",
    "        summary_text = transcript_line.replace(\"\\n\", \"<br/>\")\n",
    "\n",
    "        if \"Doctor\" in summary_text[:6]:\n",
    "            summary_text = \"DOCTOR\" + summary_text[6:]\n",
    "        if \"Patient\" in summary_text[:7]:\n",
    "            summary_text = \"PATIENT\" + summary_text[7:]\n",
    "\n",
    "        summary_paragraph = Paragraph(summary_text, body_style)\n",
    "        width, height = summary_paragraph.wrap(500, 800)\n",
    "\n",
    "        start_new_page_if_needed(height)\n",
    "        summary_paragraph.drawOn(c, 50, y_position - height + 10)\n",
    "        y_position -= height + 10\n",
    "\n",
    "    # Save the PDF file\n",
    "    if output_filename:\n",
    "        c.save()\n",
    "\n",
    "    return c.getpdfdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_maker(\n",
    "        type: typing.Literal['transcripts', 'transcripts_eval', 'transcripts_eval_improvements', 'summaries', 'summaries_eval', 'summaries_eval_improvements', 'pdfs'],\n",
    "        transcript_type: typing.Literal['full', 'short'],\n",
    "        model_name: typing.Literal['3.5', '4o-mini', '4o'],\n",
    "        patient_prompt: typing.Literal['base', 'reluctant', 'distracted'],\n",
    "        doctor_prompt: typing.Literal['base', 'improved']\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a path for saving or loading files based on the type of file and the model and prompt used.\n",
    "    \n",
    "    Args:\n",
    "        type: The type of file to create the path for (either 'transcripts', 'transcripts_eval', 'transcripts_eval_improvements', 'summaries', 'summaries_eval', 'summaries_eval_improvements').\n",
    "        transcript_type: The type of transcript to create the path for (either 'full' or 'short'). Full is the full chat transcript, while short is the extracted chat transcript.\n",
    "        model_name: The name of the model used in the transcript.\n",
    "        patient_prompt: The type of patient prompt used in the transcript.\n",
    "        doctor_prompt: The type of doctor prompt used in the transcript.\n",
    "    \"\"\"\n",
    "    # Set the folder path depending on type\n",
    "    if type == 'transcripts':\n",
    "        folder_path = '../data/transcripts'\n",
    "    elif type in ['transcripts_eval', 'transcripts_eval_improvements']:\n",
    "        folder_path = '../data/evaluations/transcripts'\n",
    "    elif type == 'summaries':\n",
    "        folder_path = '../data/summaries'\n",
    "    elif type in ['summaries_eval', 'summaries_eval_improvements']:\n",
    "        folder_path = '../data/evaluations/summaries'\n",
    "    elif type in ['pdfs']:\n",
    "        folder_path = '../data/pdfs'\n",
    "\n",
    "    # Reformat fields\n",
    "    model_name = 'gpt' + model_name.replace('4o-mini', '4o-m')\n",
    "    patient_prompt = patient_prompt[:4] + 'pat'   \n",
    "    doctor_prompt = doctor_prompt[:4] + 'doc'\n",
    "\n",
    "    # Set to csv if this is a eval file\n",
    "    if type in ['transcripts_eval', 'summaries_eval']:\n",
    "        extension = 'csv'\n",
    "    else:\n",
    "        extension = 'json'\n",
    "\n",
    "    # Pdfs are unique\n",
    "    if type in ['pdfs']:\n",
    "        return f\"{folder_path}/{type}_{transcript_type}_{model_name}_{patient_prompt}_{doctor_prompt}/\"\n",
    "\n",
    "    return f\"{folder_path}/{type}_{transcript_type}_{model_name}_{patient_prompt}_{doctor_prompt}.{extension}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Using a Random Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_1_PATH = path_maker('transcripts', 'full', '3.5', 'base', 'base')\n",
    "TRANSCRIPTS_1_PDF_PATH = path_maker('pdfs', 'full', '3.5', 'base', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/pdfs/pdfs_full_gpt3.5_basepat_basedoc/\n"
     ]
    }
   ],
   "source": [
    "print(TRANSCRIPTS_1_PDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data/pdfs/pdfs_full_gpt3.5_basepat_basedoc/' already exists.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(TRANSCRIPTS_1_PDF_PATH):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(TRANSCRIPTS_1_PDF_PATH)\n",
    "    print(f\"Directory '{TRANSCRIPTS_1_PDF_PATH}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{TRANSCRIPTS_1_PDF_PATH}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the JSON file\n",
    "with open(TRANSCRIPTS_1_PATH, 'r') as json_file:\n",
    "    patients = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_key = random.choice(list(patients.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_transcript = patients[random_key]['chat_transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_summary = summarize(patient_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your PDF file\n",
    "pdf_filename = f\"{TRANSCRIPTS_1_PDF_PATH}TEST_{random_key}_pdf.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_patient_report(patient_summary[0], patient_transcript, pdf_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate PDFs & Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_everything(transcripts_path, summaries_path, pdfs_path, model=default_model, n_transcripts=20):\n",
    "    if not os.path.exists(pdfs_path):\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(pdfs_path)\n",
    "        print(f\"Directory '{pdfs_path}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{pdfs_path}' already exists.\")\n",
    "    \n",
    "    # Open and read the JSON file\n",
    "    with open(transcripts_path, 'r') as json_file:\n",
    "        patients = json.load(json_file)\n",
    "\n",
    "    summaries = {}\n",
    "    i=0\n",
    "\n",
    "    for p_id in patients:\n",
    "        if i < n_transcripts:\n",
    "            summary = {}\n",
    "\n",
    "            p_transcript = patients[p_id]['chat_transcript']\n",
    "\n",
    "            print(f\"Generating summary for patient {p_id}\")\n",
    "\n",
    "            p_summary = summarize(patient_transcript=p_transcript, model=model)\n",
    "\n",
    "            summary['id'] = p_id\n",
    "            \n",
    "            p_summary_output = p_summary[0]\n",
    "            p_summary_output_dict = p_summary_output.to_dict()\n",
    "\n",
    "            summary['summary'] = p_summary_output_dict\n",
    "\n",
    "            summaries[str(p_id)] = summary\n",
    "\n",
    "            print(\"Summary generation successful\")\n",
    "\n",
    "            print(f\"Generating PDF for patient {p_id}\")\n",
    "\n",
    "            first_underscore_pos = pdfs_path.find(\"_\")\n",
    "            experiment_name = pdfs_path[first_underscore_pos+1:-1]\n",
    "\n",
    "            pdf_filename = f\"{pdfs_path}patient_{p_id}_{experiment_name}.pdf\"\n",
    "\n",
    "            create_patient_report(p_summary[0], p_transcript, pdf_filename)\n",
    "\n",
    "            i+=1\n",
    "    \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"Summary and PDF generation complete\")\n",
    "    print()\n",
    "    print(f\"Saving all patient summaries in summary file\")\n",
    "\n",
    "    with open(summaries_path, 'w') as json_file:\n",
    "        json.dump(summaries, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcripts 2\n",
    "- Naturally terminated transcripts\n",
    "- GPT3.5-turbo\n",
    "- Baseline patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_2_PATH = path_maker('transcripts', 'short', '3.5', 'base', 'base')\n",
    "TRANSCRIPTS_2_SUMMARIES_PATH = path_maker('summaries', 'short', '3.5', 'base', 'base')\n",
    "TRANSCRIPTS_2_PDF_PATH = path_maker('pdfs', 'short', '3.5', 'base', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data/pdfs/pdfs_short_gpt3.5_basepat_basedoc/' already exists.\n",
      "Generating summary for patient 19597377\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19597377\n",
      "Generating summary for patient 14206800\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14206800\n",
      "Generating summary for patient 17072793\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17072793\n",
      "Generating summary for patient 14584705\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14584705\n",
      "Generating summary for patient 16521649\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16521649\n",
      "Generating summary for patient 14717765\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14717765\n",
      "Generating summary for patient 15343100\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15343100\n",
      "Generating summary for patient 13228928\n",
      "Summary generation successful\n",
      "Generating PDF for patient 13228928\n",
      "Generating summary for patient 11922236\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11922236\n",
      "Generating summary for patient 15628804\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15628804\n",
      "Generating summary for patient 11562514\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11562514\n",
      "Generating summary for patient 18056245\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18056245\n",
      "Generating summary for patient 12390274\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12390274\n",
      "Generating summary for patient 10816667\n",
      "Summary generation successful\n",
      "Generating PDF for patient 10816667\n",
      "Generating summary for patient 19380754\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19380754\n",
      "Generating summary for patient 11532659\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11532659\n",
      "Generating summary for patient 19557627\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19557627\n",
      "Generating summary for patient 19291186\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19291186\n",
      "Generating summary for patient 13423238\n",
      "Summary generation successful\n",
      "Generating PDF for patient 13423238\n",
      "Generating summary for patient 11052273\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11052273\n",
      "Summary and PDF generation complete\n",
      "\n",
      "Saving all patient summaries in summary file\n"
     ]
    }
   ],
   "source": [
    "generate_everything(TRANSCRIPTS_2_PATH, TRANSCRIPTS_2_SUMMARIES_PATH, TRANSCRIPTS_2_PDF_PATH, model=default_model, n_transcripts=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcripts 3\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o-mini\n",
    "- Baseline patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_3_PATH = path_maker('transcripts', 'short', '4o-mini', 'base', 'base')\n",
    "TRANSCRIPTS_3_SUMMARIES_PATH = path_maker('summaries', 'short', '4o-mini', 'base', 'base')\n",
    "TRANSCRIPTS_3_PDF_PATH = path_maker('pdfs', 'short', '4o-mini', 'base', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_update = ChatOpenAI(temperature=0.0, model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data/pdfs/pdfs_short_gpt4o-m_basepat_basedoc/' already exists.\n",
      "Generating summary for patient 11280189\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11280189\n",
      "Generating summary for patient 14717765\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14717765\n",
      "Generating summary for patient 11477097\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11477097\n",
      "Generating summary for patient 19818404\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19818404\n",
      "Generating summary for patient 19973319\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19973319\n",
      "Generating summary for patient 12641479\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12641479\n",
      "Generating summary for patient 19124949\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19124949\n",
      "Generating summary for patient 18435540\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18435540\n",
      "Generating summary for patient 12246674\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12246674\n",
      "Generating summary for patient 19516114\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19516114\n",
      "Generating summary for patient 18080005\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18080005\n",
      "Generating summary for patient 10578325\n",
      "Summary generation successful\n",
      "Generating PDF for patient 10578325\n",
      "Generating summary for patient 16883140\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16883140\n",
      "Generating summary for patient 18836076\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18836076\n",
      "Generating summary for patient 17830851\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17830851\n",
      "Generating summary for patient 15055518\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15055518\n",
      "Generating summary for patient 11080025\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11080025\n",
      "Generating summary for patient 15389058\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15389058\n",
      "Generating summary for patient 15714042\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15714042\n",
      "Generating summary for patient 11052273\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11052273\n",
      "Summary and PDF generation complete\n",
      "\n",
      "Saving all patient summaries in summary file\n"
     ]
    }
   ],
   "source": [
    "generate_everything(TRANSCRIPTS_3_PATH, TRANSCRIPTS_3_SUMMARIES_PATH, TRANSCRIPTS_3_PDF_PATH, model=model_update, n_transcripts=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcripts 4\n",
    "\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o\n",
    "- Baseline patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_4_PATH = path_maker('transcripts', 'short', '4o', 'base', 'base')\n",
    "TRANSCRIPTS_4_SUMMARIES_PATH = path_maker('summaries', 'short', '4o', 'base', 'base')\n",
    "TRANSCRIPTS_4_PDF_PATH = path_maker('pdfs', 'short', '4o', 'base', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_update = ChatOpenAI(temperature=0.0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data/pdfs/pdfs_short_gpt4o_basepat_basedoc/' already exists.\n",
      "Generating summary for patient 17548402\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17548402\n",
      "Generating summary for patient 10045960\n",
      "Summary generation successful\n",
      "Generating PDF for patient 10045960\n",
      "Generating summary for patient 18203000\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18203000\n",
      "Generating summary for patient 19854363\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19854363\n",
      "Generating summary for patient 14755254\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14755254\n",
      "Generating summary for patient 14030143\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14030143\n",
      "Generating summary for patient 14834029\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14834029\n",
      "Generating summary for patient 11684618\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11684618\n",
      "Generating summary for patient 16777967\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16777967\n",
      "Generating summary for patient 17800278\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17800278\n",
      "Generating summary for patient 18834270\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18834270\n",
      "Generating summary for patient 11047741\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11047741\n",
      "Generating summary for patient 16661755\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16661755\n",
      "Generating summary for patient 14540393\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14540393\n",
      "Generating summary for patient 12390274\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12390274\n",
      "Generating summary for patient 12673755\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12673755\n",
      "Generating summary for patient 16339049\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16339049\n",
      "Generating summary for patient 13030232\n",
      "Summary generation successful\n",
      "Generating PDF for patient 13030232\n",
      "Generating summary for patient 19645563\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19645563\n",
      "Generating summary for patient 11052273\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11052273\n",
      "Summary and PDF generation complete\n",
      "\n",
      "Saving all patient summaries in summary file\n"
     ]
    }
   ],
   "source": [
    "generate_everything(TRANSCRIPTS_4_PATH, TRANSCRIPTS_4_SUMMARIES_PATH, TRANSCRIPTS_4_PDF_PATH, model=model_update, n_transcripts=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcripts 5\n",
    "\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o mini\n",
    "- Reluctant patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_5_PATH = path_maker('transcripts', 'short', '4o-mini', 'reluctant', 'base')\n",
    "TRANSCRIPTS_5_SUMMARIES_PATH = path_maker('summaries', 'short', '4o-mini', 'reluctant', 'base')\n",
    "TRANSCRIPTS_5_PDF_PATH = path_maker('pdfs', 'short', '4o-mini', 'reluctant', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_update = ChatOpenAI(temperature=0.0, model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data/pdfs/pdfs_short_gpt4o-m_relupat_basedoc/' already exists.\n",
      "Generating summary for patient 10112163\n",
      "Summary generation successful\n",
      "Generating PDF for patient 10112163\n",
      "Generating summary for patient 14108973\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14108973\n",
      "Generating summary for patient 15393180\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15393180\n",
      "Generating summary for patient 11169394\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11169394\n",
      "Generating summary for patient 12007928\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12007928\n",
      "Generating summary for patient 17133133\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17133133\n",
      "Generating summary for patient 15862920\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15862920\n",
      "Generating summary for patient 15911683\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15911683\n",
      "Generating summary for patient 15132645\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15132645\n",
      "Generating summary for patient 16633970\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16633970\n",
      "Generating summary for patient 17333919\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17333919\n",
      "Generating summary for patient 17659582\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17659582\n",
      "Generating summary for patient 11587903\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11587903\n",
      "Generating summary for patient 12390274\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12390274\n",
      "Generating summary for patient 13743849\n",
      "Summary generation successful\n",
      "Generating PDF for patient 13743849\n",
      "Generating summary for patient 18417736\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18417736\n",
      "Generating summary for patient 10256360\n",
      "Summary generation successful\n",
      "Generating PDF for patient 10256360\n",
      "Generating summary for patient 16252158\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16252158\n",
      "Generating summary for patient 17842643\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17842643\n",
      "Generating summary for patient 11052273\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11052273\n",
      "Summary and PDF generation complete\n",
      "\n",
      "Saving all patient summaries in summary file\n"
     ]
    }
   ],
   "source": [
    "generate_everything(TRANSCRIPTS_5_PATH, TRANSCRIPTS_5_SUMMARIES_PATH, TRANSCRIPTS_5_PDF_PATH, model=model_update, n_transcripts=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transcripts 6\n",
    "\n",
    "- Naturally terminated transcripts\n",
    "- GPT4o mini\n",
    "- Distracted patient prompt\n",
    "- Baseline doctor prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPTS_6_PATH = path_maker('transcripts', 'short', '4o-mini', 'distracted', 'base')\n",
    "TRANSCRIPTS_6_SUMMARIES_PATH = path_maker('summaries', 'short', '4o-mini', 'distracted', 'base')\n",
    "TRANSCRIPTS_6_PDF_PATH = path_maker('pdfs', 'short', '4o-mini', 'distracted', 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_update = ChatOpenAI(temperature=0.0, model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../data/pdfs/pdfs_short_gpt4o-m_distpat_basedoc/' already exists.\n",
      "Generating summary for patient 17521224\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17521224\n",
      "Generating summary for patient 17133133\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17133133\n",
      "Generating summary for patient 11642460\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11642460\n",
      "Generating summary for patient 14856000\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14856000\n",
      "Generating summary for patient 14015736\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14015736\n",
      "Generating summary for patient 14588689\n",
      "Summary generation successful\n",
      "Generating PDF for patient 14588689\n",
      "Generating summary for patient 19442084\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19442084\n",
      "Generating summary for patient 17697993\n",
      "Summary generation successful\n",
      "Generating PDF for patient 17697993\n",
      "Generating summary for patient 18670109\n",
      "Summary generation successful\n",
      "Generating PDF for patient 18670109\n",
      "Generating summary for patient 12489621\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12489621\n",
      "Generating summary for patient 19740429\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19740429\n",
      "Generating summary for patient 16114223\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16114223\n",
      "Generating summary for patient 15049237\n",
      "Summary generation successful\n",
      "Generating PDF for patient 15049237\n",
      "Generating summary for patient 16883140\n",
      "Summary generation successful\n",
      "Generating PDF for patient 16883140\n",
      "Generating summary for patient 10816667\n",
      "Summary generation successful\n",
      "Generating PDF for patient 10816667\n",
      "Generating summary for patient 19380754\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19380754\n",
      "Generating summary for patient 12178737\n",
      "Summary generation successful\n",
      "Generating PDF for patient 12178737\n",
      "Generating summary for patient 10193065\n",
      "Summary generation successful\n",
      "Generating PDF for patient 10193065\n",
      "Generating summary for patient 19843520\n",
      "Summary generation successful\n",
      "Generating PDF for patient 19843520\n",
      "Generating summary for patient 11052273\n",
      "Summary generation successful\n",
      "Generating PDF for patient 11052273\n",
      "Summary and PDF generation complete\n",
      "\n",
      "Saving all patient summaries in summary file\n"
     ]
    }
   ],
   "source": [
    "generate_everything(TRANSCRIPTS_6_PATH, TRANSCRIPTS_6_SUMMARIES_PATH, TRANSCRIPTS_6_PDF_PATH, model=model_update, n_transcripts=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
